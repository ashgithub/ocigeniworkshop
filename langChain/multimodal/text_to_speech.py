"""
What this file does:
Generates natural-sounding speech clips from text prompts using OCI-hosted GPT-Audio models. Stores the audio locally so you can test responses or feed them into downstream workflows.

Documentation to reference:
- Open AI Audio: https://developers.openai.com/api/docs/guides/audio
- OCI OpenAI compatible SDK: https://github.com/oracle-samples/oci-openai
- note oci doesnt support audio -> audio just yet (as of feb 2026)


Relevant slack channels:
- #generative-ai-users: for questions on OCI Gen AI
- #igiu-innovation-lab: general discussions on your project
- #igiu-ai-learning: help with sandbox environment or help with running this code

Env setup:
- sandbox.yaml: Contains OCI config, compartment, and profile details.
- .env: Store overrides like `VOICE_NAME` or `AUDIO_FORMAT` if you want to experiment.

How to run the file:
uv run langChain/multimodal/text_to_speech.py

Comments to important sections of file:
- Step 1: Load config and initialize the OCI OpenAI chat client.
- Step 2: Define the text prompt, voice, and output path.
- Step 3: Call GPT-Audio and extract the synthesized voice track.
- Step 4: Persist the audio file and display metadata for debugging.
"""

import base64
import os,sys
from pathlib import Path
from typing import Tuple

from dotenv import load_dotenv
from envyaml import EnvYAML


sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from oci_openai_helper import OCIOpenAIHelper

# generated by codex AI - model gpt-4.1

SANDBOX_CONFIG_FILE = "sandbox.yaml"
DEFAULT_MODEL = "openai.gpt-audio"
DEFAULT_VOICE = "alloy"
DEFAULT_AUDIO_FORMAT = "wav"
DEFAULT_PROMPT = "Is a golden retriever a good family dog?"
DEFAULT_OUTPUT = Path("scratch/dog.wav")


# Step 1: Load config and initialize clients
def load_config(config_path: str) -> EnvYAML:
    try:
        return EnvYAML(config_path)
    except FileNotFoundError as exc:
        raise SystemExit(f"Missing configuration file: {config_path}") from exc


def get_openai_client(config: EnvYAML):
    return OCIOpenAIHelper.get_sync_openai_client(config=config)


# Step 2: Define text prompt, voice, and output path
def get_speech_settings() -> Tuple[str, str, str, Path, str]:
    model = os.getenv("AUDIO_MODEL", DEFAULT_MODEL)
    voice = os.getenv("VOICE_NAME", DEFAULT_VOICE)
    audio_format = os.getenv("AUDIO_FORMAT", DEFAULT_AUDIO_FORMAT)
    prompt = os.getenv("AUDIO_PROMPT", DEFAULT_PROMPT)
    output_path = Path(os.getenv("AUDIO_OUTPUT", str(DEFAULT_OUTPUT)))
    return model, voice, audio_format, output_path, prompt


def ensure_output_dir(path: Path) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)


# Step 3: Call GPT-Audio and extract audio payload
def synthesize_audio(client, model: str, voice: str, audio_format: str, prompt: str):
    completion = client.chat.completions.create(
        model=model,
        modalities=["text", "audio"],
        audio={"voice": voice, "format": audio_format},
        messages=[{"role": "user", "content": prompt}],
    )
    choice = completion.choices[0]
    audio_b64 = choice.message.audio.data
    metadata = choice.message.audio
    usage = completion.usage.to_dict() if completion.usage else {}
    return audio_b64, metadata, usage


def decode_audio(audio_b64: str) -> bytes:
    return base64.b64decode(audio_b64)


# Step 4: Persist audio and show metadata
def save_audio(audio_bytes: bytes, path: Path) -> None:
    ensure_output_dir(path)
    path.write_bytes(audio_bytes)


def main() -> None:
    load_dotenv()
    config = load_config(SANDBOX_CONFIG_FILE)
    client = get_openai_client(config)
    model, voice, audio_format, output_path, prompt = get_speech_settings()

    print(f"Using model={model}, voice={voice}, format={audio_format}")
    audio_b64, metadata, usage = synthesize_audio(client, model, voice, audio_format, prompt)
    audio_bytes = decode_audio(audio_b64)
    save_audio(audio_bytes, output_path)

    print(f"Saved audio to {output_path.resolve()}")
    print(f"Audio metadata: {metadata}")
    print(f"Token usage: {usage}")
    print("Try changing VOICE_NAME or AUDIO_PROMPT to explore different voices.")


if __name__ == "__main__":
    main()
