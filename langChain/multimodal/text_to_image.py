"""
What this file does:
Generates brand-new images from text prompts using OCI-hosted OpenAI GPT-Image models via LangChain. Saves the output locally so you can inspect the results and reuse them in later multimodal workflows.

Documentation to reference:
- OpenAI Image : https://developers.openai.com/api/docs/guides/images-vision
- OCI OpenAI compatible SDK: https://github.com/oracle-samples/oci-openai
- LangChain: https://docs.langchain.com/oss/python/langchain/overview
- note: oci doesnt support image/edit end point yet. you we can only geneatyed image form text image -> image is not supported yet 

Relevant slack channels:
- #generative-ai-users: for questions on OCI Gen AI
- #igiu-innovation-lab: general discussions on your project
- #igiu-ai-learning: help with sandbox environment or help with running this code

Env setup:
- sandbox.yaml: Contains OCI config, compartment, and profile details. Make sure image bucket prefix and conversation store are configured if needed.
- .env: Load environment variables (e.g., profile overrides) before invoking this script.

How to run the file:
uv run langChain/multimodal/text_to_image.py

Comments to important sections of file:
- Step 1: Load sandbox config and initialize the OCI OpenAI client.
- Step 2: Define the generation prompt, model, and output path.
- Step 3: Call the GPT-Image model and decode the base64 payload.
- Step 4: Persist the image to disk and print helpful usage metrics.
"""

import base64
import os,sys
from pathlib import Path
from typing import Optional

from dotenv import load_dotenv
from envyaml import EnvYAML

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from oci_openai_helper import OCIOpenAIHelper

# generated by codex AI - model gpt-4.1

SANDBOX_CONFIG_FILE = "sandbox.yaml"
DEFAULT_MODEL = "openai.gpt-image-1.5"
DEFAULT_SIZE = "1536x1024"  # API-supported landscape preset
DEFAULT_PROMPT = "A cute baby sea otter floating on a neon surfboard"
DEFAULT_OUTPUT = Path("langChain/multimodal/otter.png")


# Step 1: Load sandbox config and initialize clients
def load_config(config_path: str) -> EnvYAML:
    try:
        return EnvYAML(config_path)
    except FileNotFoundError as exc:
        raise SystemExit(f"Missing configuration file: {config_path}") from exc


def get_openai_client(config: EnvYAML):
    return OCIOpenAIHelper.get_sync_openai_client(config=config)


# Step 2: Define prompt, model, and output path
def get_generation_settings() -> tuple[str, str, str, Path]:
    model = os.getenv("IMAGE_MODEL", DEFAULT_MODEL)
    size = os.getenv("IMAGE_SIZE", DEFAULT_SIZE)
    prompt = os.getenv("IMAGE_PROMPT", DEFAULT_PROMPT)
    output_path = Path(os.getenv("IMAGE_OUTPUT", str(DEFAULT_OUTPUT)))
    return model, size, prompt, output_path


def ensure_output_dir(path: Path) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)


# Step 3: Call GPT-Image and decode base64 payload
def generate_image(client, model: str, prompt: str, size: str) -> tuple[str, dict]:
    response = client.images.generate(
        model=model,
        prompt=prompt,
        n=1,
        size=size,
    )
    image_b64 = response.data[0].b64_json
    return image_b64, response.usage.to_dict()


def decode_image(image_b64: str) -> bytes:
    return base64.b64decode(image_b64)


# Step 4: Persist the image to disk
def save_image(image_bytes: bytes, path: Path) -> None:
    ensure_output_dir(path)
    path.write_bytes(image_bytes)


def main() -> None:
    load_dotenv()
    config = load_config(SANDBOX_CONFIG_FILE)
    client = get_openai_client(config)
    model, size, prompt, output_path = get_generation_settings()

    print(f"Using model={model}, size={size}, prompt='{prompt}'")
    image_b64, usage = generate_image(client, model, prompt, size)
    image_bytes = decode_image(image_b64)
    save_image(image_bytes, output_path)

    print(f"Saved image to {output_path.resolve()}")
    print(f"Token usage: {usage}")
    print("Experiment: update IMAGE_PROMPT or IMAGE_SIZE env vars to iterate quickly.")


if __name__ == "__main__":
    main()
