{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "679eac8d",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation (RAG) Example with OCI Generative AI & Oracle DB\n",
    "\n",
    "### What this file does:\n",
    "Demonstrates a full RAG (Retrieval-Augmented Generation) example using OCI Generative AI for embeddings and LLM, with Oracle DB for vector storage and semantic search.\n",
    "\n",
    "**Documentation to reference:**\n",
    "- OCI Gen AI: https://docs.oracle.com/en-us/iaas/Content/generative-ai/pretrained-models.htm\n",
    "- LangChain: https://docs.langchain.com/oss/python/langchain/overview\n",
    "- Oracle DB Vectors: https://docs.oracle.com/en/database/oracle/oracle-database/23/vecse/\n",
    "- OCI OpenAI compatible SDK: https://github.com/oracle-samples/oci-openai  *note: supports OpenAI, XAI & Meta models. Also supports OpenAI Responses API* \n",
    "- OCI langchain SDK: https://github.com/oracle-devrel/langchain-oci-genai  *note: as of Nov 2025 it is not compatible with langchain v1.0. supports all OCI models including Cohere*\n",
    "- OCI GenAI SDK: https://github.com/oracle/oci-python-sdk/tree/master/src/oci/generative_ai_inference/models\n",
    "\n",
    "**Relevant slack channels:**\n",
    "- #generative-ai-users: *for questions on OCI Gen AI* \n",
    "- #igiu-innovation-lab: *general discussions on your project* \n",
    "- #igiu-ai-learning: *help with sandbox environment or help with running this code* \n",
    "\n",
    "**Env setup:**\n",
    "- sandbox.yaml: Contains OCI config, compartment, DB details, and wallet path.\n",
    "- .env: Load environment variables (e.g., API keys if needed).\n",
    "- configure cwd for jupyter match your workspace python code: \n",
    "    -  vscode menu -> Settings > Extensions > Jupyter > Notebook File Root\n",
    "    -  change from `${fileDirname}` to `${workspaceFolder}`\n",
    "\n",
    "\n",
    "**How to run in notebook:**\n",
    "- Make sure your runtime environment has all dependencies and access to required config files.\n",
    "- Run the notebook cells in order.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f06f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import array\n",
    "import oci\n",
    "import oracledb\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.messages import HumanMessage\n",
    "# from langchain_oci.embeddings import OCIGenAIEmbeddings  requires langchain 0.3x, doesn't work with 1.0.0 yet\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from envyaml import EnvYAML\n",
    "\n",
    "from oci.generative_ai_inference import GenerativeAiInferenceClient\n",
    "from oci.generative_ai_inference.models import OnDemandServingMode, EmbedTextDetails\n",
    "\n",
    "from langChain.oci_openai_helper import OCIOpenAIHelper\n",
    "\n",
    "# Reference: https://docs.langchain.com/oss/python/integrations/splitters\n",
    "\n",
    "SANDBOX_CONFIG_FILE = \"sandbox.yaml\"\n",
    "load_dotenv()\n",
    "\n",
    "EMBED_MODEL = \"cohere.embed-english-light-v3.0\"\n",
    "# Available embedding models https://docs.oracle.com/en-us/iaas/Content/generative-ai/pretrained-models.htm#embed-models\n",
    "\n",
    "# cohere.embed-v4.0\n",
    "# cohere.embed-multilingual-v3.0\n",
    "# cohere.embed-multilingual-light-v3.0\n",
    "# cohere.embed-english-v3.0\n",
    "# cohere.embed-english-light-v3.0\n",
    "\n",
    "OCI_ENDPOINT = \"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\"\n",
    "\n",
    "LLM_MODEL = \"openai.gpt-4.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3aa28e",
   "metadata": {},
   "source": [
    "### Step 1: Load config and initialize clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8b77ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_path):\n",
    "    \"\"\"Load configuration from a YAML file.\"\"\"\n",
    "    try:\n",
    "        with open(config_path, 'r') as f:\n",
    "            return EnvYAML(config_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Configuration file '{config_path}' not found.\")\n",
    "        return None\n",
    "\n",
    "scfg = load_config(SANDBOX_CONFIG_FILE)\n",
    "\n",
    "config = oci.config.from_file(\n",
    "    os.path.expanduser(scfg[\"oci\"][\"configFile\"]),\n",
    "    scfg[\"oci\"][\"profile\"]\n",
    ")\n",
    "compartment_id = scfg[\"oci\"][\"compartment\"]\n",
    "table_prefix = scfg[\"db\"][\"tablePrefix\"]\n",
    "wallet_path = os.path.expanduser(scfg[\"db\"][\"walletPath\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc43042",
   "metadata": {},
   "source": [
    "### Step 2: Load and chunk the PDF document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae931139",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"./langChain/rag/Sample1.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)\n",
    "texts = [chunk.page_content for chunk in splits]\n",
    "\n",
    "print(f\"Created {len(splits)} text chunks for embedding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3199385",
   "metadata": {},
   "source": [
    "### Step 3: Generate embeddings for chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ff44d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_client = GenerativeAiInferenceClient(\n",
    "     config=config,\n",
    "     service_endpoint=OCI_ENDPOINT,\n",
    "     retry_strategy=oci.retry.NoneRetryStrategy(),\n",
    "     timeout=(10, 240),\n",
    " )\n",
    "\n",
    "def get_embed_payload(chunks, embed_type):\n",
    "    \"\"\"Build embedding payload for OCI Generative AI.\"\"\"\n",
    "    embed_text_detail = EmbedTextDetails()\n",
    "    embed_text_detail.serving_mode = OnDemandServingMode(model_id=EMBED_MODEL)\n",
    "    embed_text_detail.truncate = embed_text_detail.TRUNCATE_END\n",
    "    embed_text_detail.input_type = embed_type\n",
    "    embed_text_detail.compartment_id = compartment_id\n",
    "    embed_text_detail.inputs = chunks\n",
    "    return embed_text_detail\n",
    "\n",
    "embed_payload = get_embed_payload(texts, EmbedTextDetails.INPUT_TYPE_SEARCH_DOCUMENT)\n",
    "embed_response = embed_client.embed_text(embed_payload)\n",
    "embeddings = embed_response.data.embeddings\n",
    "\n",
    "print(f\"Generated {len(embeddings)} embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c23a5d",
   "metadata": {},
   "source": [
    "### Step 4: Set up Oracle DB connection and create vector table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea40346",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_client = OCIOpenAIHelper.get_client(\n",
    "    model_name=LLM_MODEL,\n",
    "    config=scfg\n",
    ")\n",
    "\n",
    "db_connection = oracledb.connect(\n",
    "    config_dir=wallet_path,\n",
    "    user=scfg[\"db\"][\"username\"],\n",
    "    password=scfg[\"db\"][\"password\"],\n",
    "    dsn=scfg[\"db\"][\"dsn\"],\n",
    "    wallet_location=wallet_path,\n",
    "    wallet_password=scfg[\"db\"][\"walletPass\"]\n",
    ")\n",
    "cursor = db_connection.cursor()\n",
    "\n",
    "def create_table():\n",
    "    \"\"\"Drop and create embedding table.\"\"\"\n",
    "    print(\"Creating table for embeddings...\")\n",
    "\n",
    "    # Use the prefix to avoid usage of the same table per user\n",
    "    sql_statements = [\n",
    "        f\"DROP TABLE {table_prefix}_embedding PURGE\",\n",
    "        f\"\"\"\n",
    "        CREATE TABLE {table_prefix}_embedding (\n",
    "            id NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,\n",
    "            text VARCHAR2(4000),\n",
    "            vec VECTOR,\n",
    "            source VARCHAR2(100)\n",
    "        )\n",
    "        \"\"\"\n",
    "    ]\n",
    "\n",
    "    for stmt in sql_statements:\n",
    "        try:\n",
    "            cursor.execute(stmt)\n",
    "        except Exception as e:\n",
    "            # Ignore if table doesn't exist and create a new one\n",
    "            print(f\"Skipping error: {e}\")\n",
    "\n",
    "create_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70022ef0",
   "metadata": {},
   "source": [
    "### Step 5: Insert embeddings into DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4394d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, emb in enumerate(embeddings):\n",
    "    chunk_text = texts[i][:3900]  # ensure within VARCHAR2(4000) limit according to table constraint\n",
    "    metadata_source = f\"{splits[i].metadata.get('source', 'pdf-doc')}_start_{splits[i].metadata.get('start_index', 0)}\"\n",
    "\n",
    "    cursor.execute(\n",
    "        f\"INSERT INTO {table_prefix}_embedding (text, vec, source) VALUES (:1, :2, :3)\",\n",
    "        [chunk_text, array.array(\"f\", emb), metadata_source],\n",
    "    )\n",
    "\n",
    "db_connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa26b58",
   "metadata": {},
   "source": [
    "### Step 6: Define semantic search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30014e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, top_k=3):\n",
    "    \"\"\"Perform semantic search with cosine similarity.\"\"\"\n",
    "    query_payload = get_embed_payload([query], EmbedTextDetails.INPUT_TYPE_SEARCH_QUERY)\n",
    "    query_response = embed_client.embed_text(query_payload)\n",
    "    query_emb = query_response.data.embeddings[0]\n",
    "    query_vec = array.array(\"f\", query_emb)\n",
    "\n",
    "    cursor.execute(f\"\"\"\n",
    "        SELECT text, vector_distance(vec, :1, COSINE) AS distance, source\n",
    "        FROM {table_prefix}_embedding\n",
    "        ORDER BY distance\n",
    "        FETCH FIRST {top_k} ROWS ONLY\n",
    "    \"\"\", [query_vec])\n",
    "\n",
    "    rows = cursor.fetchall()\n",
    "    return [{\"text\": r[0], \"distance\": r[1], \"source\": r[2]} for r in rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a1f555",
   "metadata": {},
   "source": [
    "### Step 7: Helper to build context from search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3e8091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context_snippet(results):\n",
    "    \"\"\"Format retrieved chunks for prompt context.\"\"\"\n",
    "    context_parts = []\n",
    "    for i, r in enumerate(results, 1):\n",
    "        snippet = r[\"text\"].replace(\"\\n\", \" \")\n",
    "        context_parts.append(f\"[{i}] (Source: {r['source']}) {snippet}\")\n",
    "    return \"\\n\\n\".join(context_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbf54dd",
   "metadata": {},
   "source": [
    "### Step 8: RAG workflow: retrieve, augment, generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9120b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_answer(query):\n",
    "    \"\"\"Perform RAG\"\"\"\n",
    "    # R: retrieve the results from knowledge base\n",
    "    results = semantic_search(query, top_k=5)\n",
    "\n",
    "    # A: augment the prompt. Build a compact context to call the agent\n",
    "    context = build_context_snippet(results)\n",
    "    context_prompt = (\n",
    "        f\"You are an assistant answering only from the provided document excerpts.\\n\"\n",
    "        f\"Use them faithfully and cite their source in square brackets.\\n\\n\"\n",
    "        f\"--- DOCUMENT EXCERPTS ---\\n{context}\\n\\n\"\n",
    "        f\"--- QUESTION ---\\n{query}\\n\\n\"\n",
    "    )\n",
    "\n",
    "    print(f\"-----------> Calling the agent with augmented context:\\n{context_prompt}\")\n",
    "\n",
    "    # G: generate the response from chat model given the full context\n",
    "    response = llm_client.invoke([HumanMessage(content=context_prompt)])\n",
    "    print(\"\\n************************** MODEL ANSWER **************************\")\n",
    "    print(response.content)\n",
    "    print(\"\\n************************** CITATIONS **************************\")\n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"[{i}] Source: {r['source']} (distance={r['distance']:.4f})\")\n",
    "    print(\"--------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9cdde2",
   "metadata": {},
   "source": [
    "### Step 9: Interactive loop for user queries (adapted for notebook; run multiple times if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda9266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    q = input(\"\\nAsk a question (or 'q' to exit): \").strip()\n",
    "    if q.lower() == \"q\":\n",
    "        break\n",
    "    rag_answer(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e9d045",
   "metadata": {},
   "source": [
    "### Close DB connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381732ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "db_connection.close()\n",
    "print(\"DB session closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
