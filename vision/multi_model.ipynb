{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCI Multimodal Vision LLM Step-by-step\n",
    "\n",
    "Beginner-friendly walkthrough using the code logic from `vision/multi_modal.py` for multimodal (image+text) prompts with Oracle Cloud's Generative AI, using only the OCI Python SDK (no LangChain needed).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "",
    "- **Dependencies:**  \n",
    "  - `oci`\n",
    "  - `python-dotenv`\n",
    "  - `envyaml`\n",
    "- **Config files:** `sandbox.yaml` (and `.env` for secrets if used)\n",
    "\n",
    "> Install missing Python packages with:\n",
    "```bash\n",
    "pip install oci python-dotenv envyaml\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "from envyaml import EnvYAML\n",
    "import oci\n",
    "import time\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Load OCI Configuration\n",
    "\n",
    "Reads details from `sandbox.yaml`. Double-check your credentials and region/profile settings if you hit a permissions error."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SANDBOX_CONFIG_FILE = \"sandbox.yaml\"\n",
    "\n",
    "def load_config(config_path):\n",
    "    try:\n",
    "        return EnvYAML(config_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Configuration file '{config_path}' not found.\")\n",
    "        return None\n",
    "\n",
    "scfg = load_config(SANDBOX_CONFIG_FILE)\n",
    "if scfg is not None and 'oci' in scfg and 'configFile' in scfg['oci'] and 'profile' in scfg['oci'] and 'compartment' in scfg['oci']:\n",
    "    config = oci.config.from_file(os.path.expanduser(scfg[\"oci\"][\"configFile\"]), scfg[\"oci\"][\"profile\"])\n",
    "    compartment_id = scfg[\"oci\"][\"compartment\"]\n",
    "else:\n",
    "    print(\"Error: Invalid configuration for OCI.\")\n",
    "    raise Exception(\"Check your 'sandbox.yaml'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Model List & Endpoint\n",
    "Set which models to test and define the (region-specific) service endpoint."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LIST = [\n",
    "    \"meta.llama-4-scout-17b-16e-instruct\",\n",
    "    \"openai.gpt-4.1\",\n",
    "    \"xai.grok-4\",\n",
    "]\n",
    "llm_service_endpoint = \"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Select and Show Your Image\n",
    "\n",
    "You can change `IMAGE_PATH` below to point to a different image if you want."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "IMAGE_PATH = 'vision/dussera-b.jpg'   # Change if you use a different image!\n",
    "display(Image(filename=IMAGE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(path):\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "IMAGE_B64 = encode_image(IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Build the Multimodal User Message\n",
    "We'll use the structure that OCI's GenerativeAI SDK expects for multimodal (text+image) inputs (as in `multi_modal.py`)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_TEXT = \"Tell me about this image\"  # You can change this!\n",
    "\n",
    "def build_user_message(img_b64, text):\n",
    "    content1 = oci.generative_ai_inference.models.TextContent()\n",
    "    content1.text = text\n",
    "    content2 = oci.generative_ai_inference.models.ImageContent()\n",
    "    image_url = oci.generative_ai_inference.models.ImageUrl()\n",
    "    image_url.url = f\"data:image/jpeg;base64,{img_b64}\"\n",
    "    content2.image_url = image_url\n",
    "    message = oci.generative_ai_inference.models.UserMessage()\n",
    "    message.content = [content1,content2]\n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Chat Request Utilities\n",
    "---",
    "Wrap up the chat message with API-friendly parameters for the request."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_request(message):\n",
    "    chat_request = oci.generative_ai_inference.models.GenericChatRequest()\n",
    "    chat_request.messages = [message]\n",
    "    chat_request.api_format = oci.generative_ai_inference.models.BaseChatRequest.API_FORMAT_GENERIC\n",
    "    chat_request.num_generations = 1\n",
    "    chat_request.is_stream = False\n",
    "    chat_request.max_tokens = 500\n",
    "    chat_request.temperature = 0.75\n",
    "    return chat_request\n",
    "\n",
    "def get_chat_detail(llm_request, compartment_id, model_id):\n",
    "    chat_detail = oci.generative_ai_inference.models.ChatDetails()\n",
    "    chat_detail.serving_mode = oci.generative_ai_inference.models.OnDemandServingMode(model_id=model_id)\n",
    "    chat_detail.compartment_id = compartment_id\n",
    "    chat_detail.chat_request = llm_request\n",
    "    return chat_detail"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Initialize the LLM Client\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_client = oci.generative_ai_inference.GenerativeAiInferenceClient(\n",
    "    config=config,\n",
    "    service_endpoint=llm_service_endpoint,\n",
    "    retry_strategy=oci.retry.NoneRetryStrategy(),\n",
    "    timeout=(10,240)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. Run Inference â€“ Compare Results!\n",
    "Loop through the models, send your multimodal prompt, and print their answers."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_id in MODEL_LIST:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"RESULTS FOR MODEL: {model_id}\\n\" + \"=\"*80)\n",
    "    start_time = time.time()\n",
    "    user_msg = build_user_message(IMAGE_B64, USER_TEXT)\n",
    "    llm_payload = get_chat_request(user_msg)\n",
    "    chat_detail = get_chat_detail(llm_payload, compartment_id, model_id)\n",
    "    llm_response = llm_client.chat(chat_detail)\n",
    "    if (llm_response is not None and hasattr(llm_response, 'data') and hasattr(llm_response.data, 'chat_response') and llm_response.data.chat_response is not None and hasattr(llm_response.data.chat_response, 'choices') and llm_response.data.chat_response.choices):\n",
    "        llm_text = llm_response.data.chat_response.choices[0].message.content[0].text\n",
    "        print(llm_text)\n",
    "    else:\n",
    "        print(\"Error: Invalid response from LLM.\")\n",
    "    end_time = time.time()\n",
    "    print(f\"\\nTime taken: {end_time - start_time:.2f} seconds\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9. Play and Explore\n",
    "\n",
    "- Change `USER_TEXT` to ask any question about your picture.\n",
    "- Swap in a different image.\n",
    "- Compare models easily!\n",
    "",
    "If you see errors, double-check credentials or configurations. Refer to comments or docs for help.\n",
    "\n",
    "---\n",
    "**Happy building!**"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
