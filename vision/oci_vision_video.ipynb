{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCI Vision Video Analysis \n",
    "\n",
    "Analyze video with Oracle Cloud Vision's pre-trained models for labels, objects, text, and faces, using the official Python SDK.\n",
    "\n",
    "This notebook is adapted from the script in `vision/oci_vision_video.py`, step-by-step for beginner-friendly workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Requirements\n",
    "\n",
    "- `sandbox.yaml` must be properly set up\n",
    "- `.env` for secrets/prefix (if needed)\n",
    "- Default video: `vision/mall.mp4` (replace with your own if needed)\n",
    "\n",
    "**Install dependencies**\n",
    "```bash\n",
    "pip install oci python-dotenv envyaml\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from envyaml import EnvYAML\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "import oci\n",
    "from oci.object_storage import ObjectStorageClient\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load OCI and Bucket Configuration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure your sandbox.yaml file is setup for your environment. You might have to specify the full path depending on  your `cwd` \n",
    "#you can also try making your cwd ofr jupyter match your workspace python code: \n",
    "#vscopde menu -> Settings > Extensions > Jupyter > Notebook File Root\n",
    "#change from ${fileDirname} to ${workspaceFolder}\n",
    "\n",
    "SANDBOX_CONFIG_FILE = \"sandbox.yaml\"\n",
    "VIDEO_PATH = Path(\"vision/mall.mp4\")\n",
    "\n",
    "def load_config(config_path):\n",
    "    try:\n",
    "        return EnvYAML(config_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Configuration file '{config_path}' not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading config: {e}\")\n",
    "        return None\n",
    "\n",
    "scfg = load_config(SANDBOX_CONFIG_FILE)\n",
    "assert scfg is not None and 'oci' in scfg and 'bucket' in scfg, 'Check your config!'\n",
    "oci_cfg = oci.config.from_file(os.path.expanduser(scfg[\"oci\"][\"configFile\"]), scfg[\"oci\"][\"profile\"])\n",
    "bucket_cfg = scfg[\"bucket\"]\n",
    "compartment_id = scfg[\"oci\"][\"compartment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Upload Video to Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file vision/mall.mp4 ...\n",
      "Upload completed!\n"
     ]
    }
   ],
   "source": [
    "def upload(oci_cfg, bucket_cfg, file_path):\n",
    "    if not file_path.exists():\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        return False\n",
    "    object_storage_client = ObjectStorageClient(oci_cfg)\n",
    "    print(f\"Uploading file {file_path} ...\")\n",
    "    object_storage_client.put_object(\n",
    "        bucket_cfg[\"namespace\"], \n",
    "        bucket_cfg[\"bucketName\"], \n",
    "        f\"{bucket_cfg['prefix']}/{file_path.name}\", \n",
    "        open(file_path, 'rb')\n",
    "    )\n",
    "    print(\"Upload completed!\")\n",
    "    return True\n",
    "\n",
    "uploaded = upload(oci_cfg, bucket_cfg, VIDEO_PATH)\n",
    "if not uploaded:\n",
    "    raise ValueError(\"Upload failed. Check your video and configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build Video Analysis Feature List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oci.ai_vision.models import (\n",
    "    ObjectLocation, ObjectListInlineInputLocation, OutputLocation,\n",
    "    CreateVideoJobDetails, VideoObjectDetectionFeature,\n",
    "    VideoFaceDetectionFeature, VideoLabelDetectionFeature, VideoTextDetectionFeature\n",
    ")\n",
    "\n",
    "def get_input_location(bucket_cfg, file_name):\n",
    "    object_location = ObjectLocation(\n",
    "        namespace_name=bucket_cfg[\"namespace\"],\n",
    "        bucket_name=bucket_cfg[\"bucketName\"],\n",
    "        object_name=f\"{bucket_cfg['prefix']}/{file_name}\",\n",
    "    )\n",
    "    return ObjectListInlineInputLocation(object_locations=[object_location])\n",
    "\n",
    "def get_output_location(bucket_cfg):\n",
    "    return OutputLocation(\n",
    "        namespace_name=bucket_cfg[\"namespace\"],\n",
    "        bucket_name=bucket_cfg[\"bucketName\"],\n",
    "        prefix=bucket_cfg[\"prefix\"],\n",
    "    )\n",
    "\n",
    "features = [\n",
    "    VideoTextDetectionFeature(),\n",
    "    VideoFaceDetectionFeature(),\n",
    "    VideoLabelDetectionFeature(),\n",
    "    VideoObjectDetectionFeature()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Submit Video Analysis Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ocid1.aivisionvideojob.oc1.phx.amaaaaaaghwivzaavx3izljexvo726qnhw5xtypontnw6h54qdi6ls2xk2ka created. State: ACCEPTED\n"
     ]
    }
   ],
   "source": [
    "vision_client = oci.ai_vision.AIServiceVisionClient(config=oci_cfg)\n",
    "job_details = CreateVideoJobDetails(\n",
    "    features=features,\n",
    "    input_location=get_input_location(bucket_cfg, VIDEO_PATH.name),\n",
    "    output_location=get_output_location(bucket_cfg),\n",
    "    compartment_id=compartment_id,\n",
    ")\n",
    "res = vision_client.create_video_job(create_video_job_details=job_details)\n",
    "job_id = None\n",
    "if res is not None and hasattr(res, 'data') and hasattr(res.data, 'id'):\n",
    "    job_id = res.data.id\n",
    "    print(f\"Job {job_id} created. State: {getattr(res.data,'lifecycle_state','?')}\")\n",
    "else:\n",
    "    print(f\"Error submitting video job: {res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Poll for Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCEPTED after 0s (progress=0.0)\n",
      "IN_PROGRESS after 5s (progress=0.0)\n",
      "IN_PROGRESS after 10s (progress=0.0)\n",
      "IN_PROGRESS after 15s (progress=0.0)\n",
      "IN_PROGRESS after 20s (progress=0.6666667)\n",
      "SUCCEEDED after 25s (progress=100.0)\n",
      "Job finished with state: SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "poll_seconds = 0\n",
    "if job_id is not None:\n",
    "    while True:\n",
    "        get_res = vision_client.get_video_job(video_job_id=job_id)\n",
    "        state = getattr(get_res.data, 'lifecycle_state', None)\n",
    "        percent = getattr(get_res.data, 'percent_complete', None)\n",
    "        print(f\"{state} after {poll_seconds}s (progress={percent})\")\n",
    "        if state not in [\"IN_PROGRESS\", \"ACCEPTED\"]:\n",
    "            break\n",
    "        time.sleep(5)\n",
    "        poll_seconds += 5\n",
    "    print(f\"Job finished with state: {state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Download and Parse Video Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labels:\n",
      "  Building\n",
      "    0-0ms  conf=0.87\n",
      "    501-1001ms  conf=0.95\n",
      "    1502-1502ms  conf=0.83\n",
      "    2503-3003ms  conf=0.95\n",
      "    3504-4004ms  conf=0.97\n",
      "    4505-5005ms  conf=0.98\n",
      "    5506-6006ms  conf=0.98\n",
      "    6507-6507ms  conf=0.98\n",
      "  Jacket\n",
      "    2503-3003ms  conf=0.91\n",
      "    3504-3504ms  conf=0.90\n",
      "  Fashion accessory\n",
      "    0-0ms  conf=0.84\n",
      "    1001-1001ms  conf=0.95\n",
      "    6006-6006ms  conf=0.93\n",
      "  Clothing\n",
      "    0-0ms  conf=0.96\n",
      "    501-1001ms  conf=0.98\n",
      "    1502-2002ms  conf=0.95\n",
      "    2503-3003ms  conf=0.98\n",
      "    3504-4004ms  conf=0.99\n",
      "    4505-5005ms  conf=0.99\n",
      "    5506-6006ms  conf=0.99\n",
      "    6507-6507ms  conf=0.98\n",
      "  Footwear\n",
      "    0-0ms  conf=0.97\n",
      "    501-1001ms  conf=0.98\n",
      "    1502-2002ms  conf=0.98\n",
      "    2503-3003ms  conf=0.97\n",
      "    3504-4004ms  conf=0.98\n",
      "    4505-5005ms  conf=0.98\n",
      "    5506-6006ms  conf=0.98\n",
      "    6507-6507ms  conf=0.98\n",
      "  Fashion\n",
      "    1001-1001ms  conf=0.95\n",
      "    6507-6507ms  conf=0.92\n",
      "  Luggage and bags\n",
      "    3504-3504ms  conf=0.92\n",
      "    4505-4505ms  conf=0.92\n",
      "    6006-6006ms  conf=0.97\n",
      "  Pedestrian\n",
      "    4505-5005ms  conf=0.92\n",
      "    5506-5506ms  conf=0.94\n",
      "  Jeans\n",
      "    2002-2002ms  conf=0.82\n",
      "  Suit\n",
      "    4004-4004ms  conf=0.83\n",
      "  Shoe\n",
      "    0-0ms  conf=0.91\n",
      "    501-501ms  conf=0.93\n",
      "    1502-2002ms  conf=0.92\n",
      "    2503-2503ms  conf=0.83\n",
      "  Trousers\n",
      "    6006-6006ms  conf=0.90\n",
      "  Vehicle\n",
      "    2002-2002ms  conf=0.89\n",
      "  Car\n",
      "    1502-2002ms  conf=0.92\n",
      "  Shopping Mall\n",
      "    3003-3003ms  conf=0.90\n",
      "    4004-4004ms  conf=0.92\n",
      "    4505-5005ms  conf=0.94\n",
      "    5506-5506ms  conf=0.94\n",
      "  Shopping\n",
      "    0-0ms  conf=0.89\n",
      "    501-1001ms  conf=0.97\n",
      "    1502-1502ms  conf=0.92\n",
      "    2503-3003ms  conf=0.97\n",
      "    3504-4004ms  conf=0.97\n",
      "    4505-5005ms  conf=0.96\n",
      "    5506-6006ms  conf=0.95\n",
      "    6507-6507ms  conf=0.92\n",
      "  Man\n",
      "    501-1001ms  conf=0.94\n",
      "    1502-2002ms  conf=0.93\n",
      "    2503-3003ms  conf=0.97\n",
      "    3504-4004ms  conf=0.98\n",
      "    4505-5005ms  conf=0.95\n",
      "    5506-5506ms  conf=0.94\n",
      "    6507-6507ms  conf=0.91\n",
      "  Woman\n",
      "    0-0ms  conf=0.96\n",
      "    501-1001ms  conf=0.98\n",
      "    1502-2002ms  conf=0.96\n",
      "    2503-3003ms  conf=0.98\n",
      "    3504-4004ms  conf=0.98\n",
      "    4505-5005ms  conf=0.98\n",
      "    5506-6006ms  conf=0.97\n",
      "    6507-6507ms  conf=0.97\n",
      "  Person\n",
      "    0-0ms  conf=0.96\n",
      "    501-1001ms  conf=0.97\n",
      "    1502-2002ms  conf=0.95\n",
      "    2503-3003ms  conf=0.99\n",
      "    3504-4004ms  conf=0.99\n",
      "    4505-5005ms  conf=0.99\n",
      "    5506-6006ms  conf=0.99\n",
      "    6507-6507ms  conf=0.98\n",
      "  Girl\n",
      "    0-0ms  conf=0.90\n",
      "    501-501ms  conf=0.88\n",
      "    6507-6507ms  conf=0.88\n",
      "  Coat\n",
      "    0-0ms  conf=0.97\n",
      "    501-1001ms  conf=0.99\n",
      "    1502-2002ms  conf=0.98\n",
      "    2503-3003ms  conf=0.99\n",
      "    3504-4004ms  conf=0.98\n",
      "    5005-5005ms  conf=0.87\n",
      "    5506-6006ms  conf=0.97\n",
      "    6507-6507ms  conf=0.94\n",
      "\n",
      "Objects:\n",
      "    501-501ms  Building  conf=0.81\n",
      "    4004-4004ms  Building  conf=0.81\n",
      "    4505-5005ms  Building  conf=0.86\n",
      "    5506-6006ms  Building  conf=0.83\n",
      "    1502-2002ms  Jacket  conf=0.85\n",
      "    2503-2503ms  Jacket  conf=0.79\n",
      "    1502-1502ms  Human face  conf=0.82\n",
      "    2503-2503ms  Human face  conf=0.85\n",
      "    3504-4004ms  Human face  conf=0.96\n",
      "    4505-5005ms  Human face  conf=0.87\n",
      "    6507-6507ms  Human face  conf=0.91\n",
      "    0-0ms  Car  conf=0.81\n",
      "    0-0ms  Footwear  conf=0.97\n",
      "    501-1001ms  Footwear  conf=0.97\n",
      "    1502-2002ms  Footwear  conf=0.96\n",
      "    2503-3003ms  Footwear  conf=0.96\n",
      "    3504-4004ms  Footwear  conf=0.97\n",
      "    4505-5005ms  Footwear  conf=0.95\n",
      "    5506-6006ms  Footwear  conf=0.97\n",
      "    6507-6507ms  Footwear  conf=0.94\n",
      "    2002-2002ms  Jeans  conf=0.84\n",
      "    4004-4004ms  Jeans  conf=0.82\n",
      "    501-1001ms  Man  conf=0.95\n",
      "    1502-2002ms  Man  conf=0.94\n",
      "    2503-3003ms  Man  conf=0.90\n",
      "    3504-4004ms  Man  conf=0.94\n",
      "    4505-5005ms  Man  conf=0.95\n",
      "    5506-6006ms  Man  conf=0.93\n",
      "    6507-6507ms  Man  conf=0.93\n",
      "    0-0ms  Woman  conf=0.91\n",
      "    501-1001ms  Woman  conf=0.94\n",
      "    1502-2002ms  Woman  conf=0.94\n",
      "    2503-3003ms  Woman  conf=0.94\n",
      "    3504-4004ms  Woman  conf=0.93\n",
      "    4505-5005ms  Woman  conf=0.92\n",
      "    5506-6006ms  Woman  conf=0.89\n",
      "    6507-6507ms  Woman  conf=0.83\n",
      "    0-0ms  Person  conf=0.90\n",
      "    3504-3504ms  Person  conf=0.96\n",
      "    0-0ms  Coat  conf=0.80\n",
      "    1001-1001ms  Coat  conf=0.85\n",
      "    1502-2002ms  Coat  conf=0.84\n",
      "    2503-3003ms  Coat  conf=0.85\n",
      "    3504-4004ms  Coat  conf=0.89\n",
      "    4505-5005ms  Coat  conf=0.85\n",
      "    5506-6006ms  Coat  conf=0.87\n",
      "\n",
      "Faces:\n",
      "    0-0ms  Face  conf=0.93\n",
      "    501-1001ms  Face  conf=0.93\n",
      "    1502-2002ms  Face  conf=0.94\n",
      "    2503-3003ms  Face  conf=0.93\n",
      "    3504-4004ms  Face  conf=0.95\n",
      "    4505-5005ms  Face  conf=0.93\n",
      "    5506-6006ms  Face  conf=0.93\n",
      "    6507-6507ms  Face  conf=0.94\n"
     ]
    }
   ],
   "source": [
    "def pretty_print_response(data):\n",
    "    if not isinstance(data, dict):\n",
    "        return print(\"Not a dict response!\")\n",
    "    video_labels = data.get(\"videoLabels\", [])\n",
    "    if video_labels:\n",
    "        print(\"\\nLabels:\")\n",
    "        for lab in video_labels:\n",
    "            print(f\"  {lab.get('name', 'Unknown')}\")\n",
    "            for seg in lab.get(\"segments\", []):\n",
    "                span = seg.get(\"videoSegment\", {})\n",
    "                start = span.get(\"startTimeOffsetMs\", \"N/A\")\n",
    "                end = span.get(\"endTimeOffsetMs\", \"N/A\")\n",
    "                conf = seg.get(\"confidence\", 0)\n",
    "                print(f\"    {start}-{end}ms  conf={conf:.2f}\")\n",
    "    video_objects = data.get(\"videoObjects\", [])\n",
    "    if video_objects:\n",
    "        print(\"\\nObjects:\")\n",
    "        for obj in video_objects:\n",
    "            label = obj.get(\"name\", \"Unknown\")\n",
    "            for seg in obj.get(\"segments\", []):\n",
    "                span = seg.get(\"videoSegment\", {})\n",
    "                start = span.get(\"startTimeOffsetMs\", \"N/A\")\n",
    "                end = seg.get(\"videoSegment\", {}).get(\"endTimeOffsetMs\", \"N/A\")\n",
    "                conf = seg.get(\"confidence\", 0)\n",
    "                print(f\"    {start}-{end}ms  {label}  conf={conf:.2f}\")\n",
    "    video_texts = data.get(\"videoTexts\", [])\n",
    "    if video_texts:\n",
    "        print(\"\\nText Lines:\")\n",
    "        for txt in video_texts:\n",
    "            content = txt.get(\"text\", \"\")\n",
    "            for seg in txt.get(\"segments\", []):\n",
    "                span = seg.get(\"videoSegment\", {})\n",
    "                start = span.get(\"startTimeOffsetMs\", \"N/A\")\n",
    "                end = span.get(\"endTimeOffsetMs\", \"N/A\")\n",
    "                conf = seg.get(\"confidence\", 0)\n",
    "                print(f\"    {start}-{end}ms  \\\"{content}\\\"  conf={conf:.2f}\")\n",
    "    video_faces = data.get(\"videoFaces\", [])\n",
    "    if video_faces:\n",
    "        print(\"\\nFaces:\")\n",
    "        for face in video_faces:\n",
    "            for seg in face.get(\"segments\", []):\n",
    "                span = seg.get(\"videoSegment\", {})\n",
    "                start = span.get(\"startTimeOffsetMs\", \"N/A\")\n",
    "                end = span.get(\"endTimeOffsetMs\", \"N/A\")\n",
    "                conf = seg.get(\"confidence\", 0)\n",
    "                print(f\"    {start}-{end}ms  Face  conf={conf:.2f}\")\n",
    "    if not any([video_labels, video_objects, video_texts, video_faces]):\n",
    "        print(\"No features detected.\")\n",
    "\n",
    "if job_id is not None and state == \"SUCCEEDED\":\n",
    "    object_storage_client = ObjectStorageClient(oci_cfg)\n",
    "    prefix = bucket_cfg['prefix']\n",
    "    object_name = f\"{prefix}/{job_id}/{prefix}/{VIDEO_PATH.name}.json\"\n",
    "    response = object_storage_client.get_object(\n",
    "        bucket_cfg['namespace'], bucket_cfg['bucketName'], object_name)\n",
    "    if hasattr(response, 'data') and hasattr(response.data, 'content'):\n",
    "        json_data = json.loads(response.data.content.decode('utf-8'))\n",
    "        pretty_print_response(json_data)\n",
    "    else:\n",
    "        print('Failed to download or parse job results!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Done! Try using different video files, and experiment with features/models.\n",
    "\n",
    "some project ideas\n",
    "-  report a person entering a builting\n",
    "-  report when you see a person but not a helmet "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
