{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCI Vision Video Analysis (Beginner Notebook)\n",
    "\n",
    "Analyze video with Oracle Cloud Vision's pre-trained models for labels, objects, text, and faces, using the official Python SDK.\n",
    "\n",
    "This notebook is adapted from the script in `vision/oci_vision_video.py`, step-by-step for beginner-friendly workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Requirements\n",
    "\n",
    "- `sandbox.yaml` must be properly set up\n",
    "- `.env` for secrets/prefix (if needed)\n",
    "- Default video: `vision/mall.mp4` (replace with your own if needed)\n",
    "\n",
    "**Install dependencies**\n",
    "```bash\n",
    "pip install oci python-dotenv envyaml\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from envyaml import EnvYAML\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "import oci\n",
    "from oci.object_storage import ObjectStorageClient\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load OCI and Bucket Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SANDBOX_CONFIG_FILE = \"sandbox.yaml\"\n",
    "VIDEO_PATH = Path(\"vision/mall.mp4\")\n",
    "\n",
    "def load_config(config_path):\n",
    "    try:\n",
    "        return EnvYAML(config_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Configuration file '{config_path}' not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading config: {e}\")\n",
    "        return None\n",
    "\n",
    "scfg = load_config(SANDBOX_CONFIG_FILE)\n",
    "assert scfg is not None and 'oci' in scfg and 'bucket' in scfg, 'Check your config!'\n",
    "oci_cfg = oci.config.from_file(os.path.expanduser(scfg[\"oci\"][\"configFile\"]), scfg[\"oci\"][\"profile\"])\n",
    "bucket_cfg = scfg[\"bucket\"]\n",
    "compartment_id = scfg[\"oci\"][\"compartment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Upload Video to Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload(oci_cfg, bucket_cfg, file_path):\n",
    "    if not file_path.exists():\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        return False\n",
    "    object_storage_client = ObjectStorageClient(oci_cfg)\n",
    "    print(f\"Uploading file {file_path} ...\")\n",
    "    object_storage_client.put_object(\n",
    "        bucket_cfg[\"namespace\"], \n",
    "        bucket_cfg[\"bucketName\"], \n",
    "        f\"{bucket_cfg['prefix']}/{file_path.name}\", \n",
    "        open(file_path, 'rb')\n",
    "    )\n",
    "    print(\"Upload completed!\")\n",
    "    return True\n",
    "\n",
    "uploaded = upload(oci_cfg, bucket_cfg, VIDEO_PATH)\n",
    "if not uploaded:\n",
    "    raise ValueError(\"Upload failed. Check your video and configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build Video Analysis Feature List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oci.ai_vision.models import (\n",
    "    ObjectLocation, ObjectListInlineInputLocation, OutputLocation,\n",
    "    CreateVideoJobDetails, VideoObjectDetectionFeature,\n",
    "    VideoFaceDetectionFeature, VideoLabelDetectionFeature, VideoTextDetectionFeature\n",
    ")\n",
    "\n",
    "def get_input_location(bucket_cfg, file_name):\n",
    "    object_location = ObjectLocation(\n",
    "        namespace_name=bucket_cfg[\"namespace\"],\n",
    "        bucket_name=bucket_cfg[\"bucketName\"],\n",
    "        object_name=f\"{bucket_cfg['prefix']}/{file_name}\",\n",
    "    )\n",
    "    return ObjectListInlineInputLocation(object_locations=[object_location])\n",
    "\n",
    "def get_output_location(bucket_cfg):\n",
    "    return OutputLocation(\n",
    "        namespace_name=bucket_cfg[\"namespace\"],\n",
    "        bucket_name=bucket_cfg[\"bucketName\"],\n",
    "        prefix=bucket_cfg[\"prefix\"],\n",
    "    )\n",
    "\n",
    "features = [\n",
    "    VideoTextDetectionFeature(),\n",
    "    VideoFaceDetectionFeature(),\n",
    "    VideoLabelDetectionFeature(),\n",
    "    VideoObjectDetectionFeature()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Submit Video Analysis Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_client = oci.ai_vision.AIServiceVisionClient(config=oci_cfg)\n",
    "job_details = CreateVideoJobDetails(\n",
    "    features=features,\n",
    "    input_location=get_input_location(bucket_cfg, VIDEO_PATH.name),\n",
    "    output_location=get_output_location(bucket_cfg),\n",
    "    compartment_id=compartment_id,\n",
    ")\n",
    "res = vision_client.create_video_job(create_video_job_details=job_details)\n",
    "job_id = None\n",
    "if res is not None and hasattr(res, 'data') and hasattr(res.data, 'id'):\n",
    "    job_id = res.data.id\n",
    "    print(f\"Job {job_id} created. State: {getattr(res.data,'lifecycle_state','?')}\")\n",
    "else:\n",
    "    print(f\"Error submitting video job: {res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Poll for Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "poll_seconds = 0\n",
    "if job_id is not None:\n",
    "    while True:\n",
    "        get_res = vision_client.get_video_job(video_job_id=job_id)\n",
    "        state = getattr(get_res.data, 'lifecycle_state', None)\n",
    "        percent = getattr(get_res.data, 'percent_complete', None)\n",
    "        print(f\"{state} after {poll_seconds}s (progress={percent})\")\n",
    "        if state not in [\"IN_PROGRESS\", \"ACCEPTED\"]:\n",
    "            break\n",
    "        time.sleep(5)\n",
    "        poll_seconds += 5\n",
    "    print(f\"Job finished with state: {state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Download and Parse Video Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_response(data):\n",
    "    if not isinstance(data, dict):\n",
    "        return print(\"Not a dict response!\")\n",
    "    video_labels = data.get(\"videoLabels\", [])\n",
    "    if video_labels:\n",
    "        print(\"\\nLabels:\")\n",
    "        for lab in video_labels:\n",
    "            print(f\"  {lab.get('name', 'Unknown')}\")\n",
    "            for seg in lab.get(\"segments\", []):\n",
    "                span = seg.get(\"videoSegment\", {})\n",
    "                start = span.get(\"startTimeOffsetMs\", \"N/A\")\n",
    "                end = span.get(\"endTimeOffsetMs\", \"N/A\")\n",
    "                conf = seg.get(\"confidence\", 0)\n",
    "                print(f\"    {start}-{end}ms  conf={conf:.2f}\")\n",
    "    video_objects = data.get(\"videoObjects\", [])\n",
    "    if video_objects:\n",
    "        print(\"\\nObjects:\")\n",
    "        for obj in video_objects:\n",
    "            label = obj.get(\"name\", \"Unknown\")\n",
    "            for seg in obj.get(\"segments\", []):\n",
    "                span = seg.get(\"videoSegment\", {})\n",
    "                start = span.get(\"startTimeOffsetMs\", \"N/A\")\n",
    "                end = seg.get(\"videoSegment\", {}).get(\"endTimeOffsetMs\", \"N/A\")\n",
    "                conf = seg.get(\"confidence\", 0)\n",
    "                print(f\"    {start}-{end}ms  {label}  conf={conf:.2f}\")\n",
    "    video_texts = data.get(\"videoTexts\", [])\n",
    "    if video_texts:\n",
    "        print(\"\\nText Lines:\")\n",
    "        for txt in video_texts:\n",
    "            content = txt.get(\"text\", \"\")\n",
    "            for seg in txt.get(\"segments\", []):\n",
    "                span = seg.get(\"videoSegment\", {})\n",
    "                start = span.get(\"startTimeOffsetMs\", \"N/A\")\n",
    "                end = span.get(\"endTimeOffsetMs\", \"N/A\")\n",
    "                conf = seg.get(\"confidence\", 0)\n",
    "                print(f\"    {start}-{end}ms  \\\"{content}\\\"  conf={conf:.2f}\")\n",
    "    video_faces = data.get(\"videoFaces\", [])\n",
    "    if video_faces:\n",
    "        print(\"\\nFaces:\")\n",
    "        for face in video_faces:\n",
    "            for seg in face.get(\"segments\", []):\n",
    "                span = seg.get(\"videoSegment\", {})\n",
    "                start = span.get(\"startTimeOffsetMs\", \"N/A\")\n",
    "                end = span.get(\"endTimeOffsetMs\", \"N/A\")\n",
    "                conf = seg.get(\"confidence\", 0)\n",
    "                print(f\"    {start}-{end}ms  Face  conf={conf:.2f}\")\n",
    "    if not any([video_labels, video_objects, video_texts, video_faces]):\n",
    "        print(\"No features detected.\")\n",
    "\n",
    "if job_id is not None and state == \"SUCCEEDED\":\n",
    "    object_storage_client = ObjectStorageClient(oci_cfg)\n",
    "    prefix = bucket_cfg['prefix']\n",
    "    object_name = f\"{prefix}/{job_id}/{prefix}/{VIDEO_PATH.name}.json\"\n",
    "    response = object_storage_client.get_object(\n",
    "        bucket_cfg['namespace'], bucket_cfg['bucketName'], object_name)\n",
    "    if hasattr(response, 'data') and hasattr(response.data, 'content'):\n",
    "        json_data = json.loads(response.data.content.decode('utf-8'))\n",
    "        pretty_print_response(json_data)\n",
    "    else:\n",
    "        print('Failed to download or parse job results!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Done! Try using different video files, and experiment with features/models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
