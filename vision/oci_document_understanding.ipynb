{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCI Document Understanding (Beginner Notebook)\n",
    "\n",
    "Analyze receipts, invoices, or documents in your OCI bucket with Oracle's Gen AI Document Understanding. This walkthrough notebook is adapted from the logic in `vision/oci_document_understanding.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup:**\n",
    "- `sandbox.yaml` and `.env` configured for your cloud tenancy and bucket\n",
    "- Your input file (default: `vision/receipt.png`, or change path as needed)\n",
    "```bash\n",
    "pip install oci python-dotenv envyaml\n",
    "```\n",
    "You only need to upload your file into Object Storage; the script below will do that step for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from envyaml import EnvYAML\n",
    "from pathlib import Path\n",
    "import oci\n",
    "from oci.object_storage import ObjectStorageClient\n",
    "import json\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configuration\n",
    "Reads your `sandbox.yaml` for credentials and bucket info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SANDBOX_CONFIG_FILE = \"sandbox.yaml\"\n",
    "FILE_TO_ANALYZE = Path(\"./vision/receipt.png\")  # Change to your input file if desired\n",
    "\n",
    "def load_config(config_path):\n",
    "    try:\n",
    "        with open(config_path, 'r') as f:\n",
    "            return EnvYAML(config_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Configuration file '{config_path}' not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading config: {e}\")\n",
    "        return None\n",
    "\n",
    "scfg = load_config(SANDBOX_CONFIG_FILE)\n",
    "assert scfg is not None and 'oci' in scfg and 'bucket' in scfg, \"Check your sandbox.yaml config!\"\n",
    "oci_cfg = oci.config.from_file(os.path.expanduser(scfg[\"oci\"][\"configFile\"]), scfg[\"oci\"][\"profile\"])\n",
    "bucket_cfg = scfg[\"bucket\"]\n",
    "compartment_id = scfg[\"oci\"][\"compartment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Image/PDF to Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload(oci_cfg, bucket_cfg, file_path):\n",
    "    if not file_path.exists():\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        return False\n",
    "    object_storage_client = ObjectStorageClient(oci_cfg)\n",
    "    print(f\"Uploading file {file_path} ...\")\n",
    "    object_storage_client.put_object(\n",
    "        bucket_cfg['namespace'],\n",
    "        bucket_cfg['bucketName'],\n",
    "        f\"{bucket_cfg['prefix']}/{file_path.name}\",\n",
    "        open(file_path, 'rb')\n",
    "    )\n",
    "    print(\"Upload completed!\")\n",
    "    return True\n",
    "\n",
    "uploaded = upload(oci_cfg, bucket_cfg, FILE_TO_ANALYZE)\n",
    "if not uploaded:\n",
    "    raise Exception(\"Upload failed. Check file path and sandbox.yaml config.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Document Understanding Client & Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dus_client = oci.ai_document.AIServiceDocumentClientCompositeOperations(\n",
    "    oci.ai_document.AIServiceDocumentClient(config=oci_cfg)\n",
    ")\n",
    "\n",
    "def get_input_location(bucket_cfg):\n",
    "    object_location = oci.ai_document.models.ObjectLocation()\n",
    "    object_location.namespace_name = bucket_cfg[\"namespace\"]\n",
    "    object_location.bucket_name = bucket_cfg[\"bucketName\"]\n",
    "    object_location.object_name = f\"{bucket_cfg['prefix']}/{os.path.basename(FILE_TO_ANALYZE)}\"\n",
    "    return object_location\n",
    "\n",
    "def get_output_location(bucket_cfg):\n",
    "    object_location = oci.ai_document.models.OutputLocation()\n",
    "    object_location.namespace_name = bucket_cfg[\"namespace\"]\n",
    "    object_location.bucket_name = bucket_cfg[\"bucketName\"]\n",
    "    object_location.prefix = f\"{bucket_cfg['prefix']}\"\n",
    "    return object_location\n",
    "\n",
    "def create_processor(features, prefix, compartmentid, bucket_cfg):\n",
    "    display_name = f\"{prefix}-test\"\n",
    "    job_details = oci.ai_document.models.CreateProcessorJobDetails(\n",
    "        display_name=display_name,\n",
    "        compartment_id=compartmentid,\n",
    "        input_location=oci.ai_document.models.ObjectStorageLocations(\n",
    "            object_locations=[get_input_location(bucket_cfg)]),\n",
    "        output_location=get_output_location(bucket_cfg),\n",
    "        processor_config=oci.ai_document.models.GeneralProcessorConfig(features=features)\n",
    "    )\n",
    "    return job_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features: classification, language, key-value, tables, text\n",
    "features = [\n",
    "    oci.ai_document.models.DocumentClassificationFeature(),\n",
    "    oci.ai_document.models.DocumentLanguageClassificationFeature(),\n",
    "    oci.ai_document.models.DocumentKeyValueExtractionFeature(),\n",
    "    oci.ai_document.models.DocumentTableExtractionFeature(),\n",
    "    oci.ai_document.models.DocumentTextExtractionFeature()\n",
    "]\n",
    "prefix = bucket_cfg['prefix']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Job and Wait for Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_processor_job_callback(times_called, response):\n",
    "    print(\"Waiting for processor lifecycle state to go into succeeded state:\", getattr(response, 'data', response))\n",
    "\n",
    "processor_res = dus_client.create_processor_job_and_wait_for_state(\n",
    "    create_processor_job_details=create_processor(features, prefix, compartment_id, bucket_cfg),\n",
    "    wait_for_states=[oci.ai_document.models.ProcessorJob.LIFECYCLE_STATE_SUCCEEDED],\n",
    "    waiter_kwargs={\"wait_callback\": create_processor_job_callback}\n",
    ")\n",
    "\n",
    "processor_job = None\n",
    "if (processor_res and processor_res is not oci.util.Sentinel):\n",
    "    data = getattr(processor_res, 'data', None)\n",
    "    request_id = getattr(processor_res, 'request_id', None)\n",
    "    if (data is not None and data is not oci.util.Sentinel and\n",
    "        hasattr(data, 'lifecycle_state') and\n",
    "        data.lifecycle_state == oci.ai_document.models.ProcessorJob.LIFECYCLE_STATE_SUCCEEDED):\n",
    "        processor_job = data\n",
    "        print(f\"Processor job succeeded with lifecycle state: {processor_job.lifecycle_state} and request ID: {request_id}.\")\n",
    "    else:\n",
    "        print(\"Processor job did not succeed.\")\n",
    "else:\n",
    "    print(\"Processor job creation failed or timed out.\")\n",
    "\n",
    "if processor_job is None:\n",
    "    raise Exception(\"Processor job failed to complete successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Display Results from Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_storage_client = oci.object_storage.ObjectStorageClient(config=oci_cfg)\n",
    "namespace = bucket_cfg['namespace']\n",
    "bucket_name = bucket_cfg['bucketName']\n",
    "if processor_job is not None and hasattr(processor_job, 'id'):\n",
    "    result_object_name = (\n",
    "        f\"{prefix}/{processor_job.id}/{namespace}_{bucket_name}/results/{prefix}/{FILE_TO_ANALYZE.name}.json\"\n",
    "    )\n",
    "    response = object_storage_client.get_object(\n",
    "        namespace_name=namespace,\n",
    "        bucket_name=bucket_name,\n",
    "        object_name=result_object_name\n",
    "    )\n",
    "    if response is not None and hasattr(response, 'data') and hasattr(response.data, 'content'):\n",
    "        json_data = json.loads(response.data.content.decode('utf-8'))\n",
    "        print(\"Analysis complete! Document Understanding Results:\")\n",
    "        print(json.dumps(json_data, indent=2))\n",
    "    else:\n",
    "        print('Failed to retrieve results or parse.' )\n",
    "else:\n",
    "    print('Error: Invalid processor job.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Parse and Summarize Key Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response(json_data):\n",
    "    doc_type = json_data.get('detectedDocumentTypes', [{}])[0].get('documentType', 'N/A')\n",
    "    lang = json_data.get('detectedLanguages', [{}])[0].get('language', 'N/A')\n",
    "    print(f\"Detected Document Type: {doc_type}\")\n",
    "    print(f\"Detected Language: {lang}\")\n",
    "    pages = json_data.get('pages', [])\n",
    "    if not pages:\n",
    "        print(\"No pages found in response.\")\n",
    "        return\n",
    "    for page_idx, page in enumerate(pages, start=1):\n",
    "        print(f\"\\n--- Page {page_idx} ---\")\n",
    "        fields = page.get('documentFields', [])\n",
    "        if not fields:\n",
    "            print(\"No document fields extracted on this page.\")\n",
    "            continue\n",
    "        for field in fields:\n",
    "            if field['fieldType'] == 'KEY_VALUE':\n",
    "                label = field['fieldLabel']['name']\n",
    "                value = field['fieldValue']\n",
    "                if value['valueType'] == 'STRING':\n",
    "                    print(f\"{label}: {value['text']}\")\n",
    "                elif value['valueType'] == 'NUMBER':\n",
    "                    print(f\"{label}: {value['value']}\")\n",
    "                elif value['valueType'] == 'DATE':\n",
    "                    print(f\"{label}: {value['text']} ({value['value']})\")\n",
    "            elif field['fieldType'] == 'LINE_ITEM_GROUP':\n",
    "                print(f\"{field['fieldLabel']['name']}:\")\n",
    "                value = field['fieldValue']\n",
    "                items = value.get('items', [])\n",
    "                for item in items:\n",
    "                    name = next((f['fieldValue']['text'] for f in item['fieldValue']['items'] if f['fieldLabel']['name']=='Name'), 'N/A')\n",
    "                    quantity = next((f['fieldValue']['value'] for f in item['fieldValue']['items'] if f['fieldLabel']['name']=='Quantity'), 'N/A')\n",
    "                    unit_price = next((f['fieldValue']['value'] for f in item['fieldValue']['items'] if f['fieldLabel']['name']=='UnitPrice'), 'N/A')\n",
    "                    amount = next((f['fieldValue']['value'] for f in item['fieldValue']['items'] if f['fieldLabel']['name']=='Amount'), 'N/A')\n",
    "                    print(f\"  - {name}: Qty {quantity} @ ${unit_price} = ${amount}\")\n",
    "            else:\n",
    "                print(f\"Unsupported field type: {field['fieldType']}\")\n",
    "\n",
    "# To use:\n",
    "# parse_response(json_data)  # (Run this cell after the above to get nicely formatted output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
