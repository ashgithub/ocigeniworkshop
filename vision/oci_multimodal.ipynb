{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCI Multimodal Vision LLM Step-by-step\n",
    "\n",
    "### What this file does:\n",
    "Demonstrates multimodal (image+text) prompts with Oracle Cloud's Generative AI, using only the OCI Python SDK (no LangChain needed).\n",
    "\n",
    "**Documentation to reference:**\n",
    "- OCI Gen AI: https://docs.oracle.com/en-us/iaas/Content/generative-ai/home.htm\n",
    "- OCI Python SDK: https://github.com/oracle/oci-python-sdk/tree/master/src/oci/generative_ai_inference\n",
    "\n",
    "**Relevant slack channels:**\n",
    "- #generative-ai-users: for questions on OCI Gen AI\n",
    "- #igiu-innovation-lab: general discussions on your project\n",
    "- #igiu-ai-learning: help with sandbox environment or help with running this code\n",
    "\n",
    "**Env setup:**\n",
    "- sandbox.yaml: Contains OCI config and compartment.\n",
    "- .env: Load environment variables if needed.\n",
    "\n",
    "**How to run in notebook:**\n",
    "- Make sure your runtime environment has all dependencies and access to required config files.\n",
    "- Run the notebook cells in order.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "- **Dependencies:**  \n",
    "  - `oci`\n",
    "  - `python-dotenv`\n",
    "  - `envyaml`\n",
    "- **Config files:** `sandbox.yaml` (and `.env` for secrets if used)\n",
    "\n",
    "> Install missing Python packages with:\n",
    "```bash\n",
    "pip install oci python-dotenv envyaml\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f8e306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "from envyaml import EnvYAML\n",
    "import oci\n",
    "import time\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1b8879",
   "metadata": {},
   "source": [
    "## 2. Load OCI Configuration\n",
    "\n",
    "Reads details from `sandbox.yaml`. Double-check your credentials and region/profile settings if you hit a permissions error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a25667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure your sandbox.yaml file is set up for your environment. You might have to specify the full path depending on your `cwd`.\n",
    "# You can also try making your cwd for jupyter match your workspace python code:\n",
    "# vscode menu -> Settings > Extensions > Jupyter > Notebook File Root\n",
    "# change from ${fileDirname} to ${workspaceFolder}\n",
    "\n",
    "SANDBOX_CONFIG_FILE = \"sandbox.yaml\"\n",
    "\n",
    "def load_config(config_path):\n",
    "    try:\n",
    "        return EnvYAML(config_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Configuration file '{config_path}' not found.\")\n",
    "        return None\n",
    "\n",
    "scfg = load_config(SANDBOX_CONFIG_FILE)\n",
    "if scfg is not None and 'oci' in scfg and 'configFile' in scfg['oci'] and 'profile' in scfg['oci'] and 'compartment' in scfg['oci']:\n",
    "    config = oci.config.from_file(os.path.expanduser(scfg[\"oci\"][\"configFile\"]), scfg[\"oci\"][\"profile\"])\n",
    "    compartment_id = scfg[\"oci\"][\"compartment\"]\n",
    "else:\n",
    "    print(\"Error: Invalid configuration for OCI.\")\n",
    "    raise Exception(\"Check your 'sandbox.yaml'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b395b6b0",
   "metadata": {},
   "source": [
    "## 3. Model List & Endpoint\n",
    "Set which models to test and define the (region-specific) service endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5226080",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LIST = [\n",
    "    \"meta.llama-4-scout-17b-16e-instruct\",\n",
    "    \"openai.gpt-4.1\",\n",
    "    \"xai.grok-4\",\n",
    "]\n",
    "llm_service_endpoint = \"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace65b79",
   "metadata": {},
   "source": [
    "## 4. Select and Show Your Image\n",
    "\n",
    "You can change `IMAGE_PATH` below to point to a different image if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adfddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "IMAGE_PATH = 'vision/dussera-b.jpg'   # Change if you use a different image!\n",
    "display(Image(filename=IMAGE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4eb077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(path):\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "IMAGE_B64 = encode_image(IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c4771d",
   "metadata": {},
   "source": [
    "## 5. Build the Multimodal User Message\n",
    "We'll use the structure that OCI's GenerativeAI SDK expects for multimodal (text+image) inputs (as in `multi_modal.py`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e5f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_TEXT = \"Tell me about this image\"  # You can change this!\n",
    "\n",
    "def build_user_message(img_b64, text):\n",
    "    content1 = oci.generative_ai_inference.models.TextContent()\n",
    "    content1.text = text\n",
    "    content2 = oci.generative_ai_inference.models.ImageContent()\n",
    "    image_url = oci.generative_ai_inference.models.ImageUrl()\n",
    "    image_url.url = f\"data:image/jpeg;base64,{img_b64}\"\n",
    "    content2.image_url = image_url\n",
    "    message = oci.generative_ai_inference.models.UserMessage()\n",
    "    message.content = [content1,content2]\n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75776152",
   "metadata": {},
   "source": [
    "## 6. Chat Request Utilities\n",
    "---\n",
    "Wrap up the chat message with API-friendly parameters for the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a35544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_request(message):\n",
    "    chat_request = oci.generative_ai_inference.models.GenericChatRequest()\n",
    "    chat_request.messages = [message]\n",
    "    chat_request.api_format = oci.generative_ai_inference.models.BaseChatRequest.API_FORMAT_GENERIC\n",
    "    chat_request.num_generations = 1\n",
    "    chat_request.is_stream = False\n",
    "    chat_request.max_tokens = 500\n",
    "    chat_request.temperature = 0.75\n",
    "    return chat_request\n",
    "\n",
    "def get_chat_detail(llm_request, compartment_id, model_id):\n",
    "    chat_detail = oci.generative_ai_inference.models.ChatDetails()\n",
    "    chat_detail.serving_mode = oci.generative_ai_inference.models.OnDemandServingMode(model_id=model_id)\n",
    "    chat_detail.compartment_id = compartment_id\n",
    "    chat_detail.chat_request = llm_request\n",
    "    return chat_detail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71b657c",
   "metadata": {},
   "source": [
    "## 7. Initialize the LLM Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c3bac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_client = oci.generative_ai_inference.GenerativeAiInferenceClient(\n",
    "    config=config,\n",
    "    service_endpoint=llm_service_endpoint,\n",
    "    retry_strategy=oci.retry.NoneRetryStrategy(),\n",
    "    timeout=(10,240)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de3b34d",
   "metadata": {},
   "source": [
    "## 8. Run Inference ‚Äì Compare Results!\n",
    "Loop through the models, send your multimodal prompt, and print their answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ad9d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_id in MODEL_LIST:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"RESULTS FOR MODEL: {model_id}\\n\" + \"=\"*80)\n",
    "    start_time = time.time()\n",
    "    user_msg = build_user_message(IMAGE_B64, USER_TEXT)\n",
    "    llm_payload = get_chat_request(user_msg)\n",
    "    chat_detail = get_chat_detail(llm_payload, compartment_id, model_id)\n",
    "    llm_response = llm_client.chat(chat_detail)\n",
    "    if (llm_response is not None and hasattr(llm_response, 'data') and hasattr(llm_response.data, 'chat_response') and llm_response.data.chat_response is not None and hasattr(llm_response.data.chat_response, 'choices') and llm_response.data.chat_response.choices):\n",
    "        llm_text = llm_response.data.chat_response.choices[0].message.content[0].text\n",
    "        print(llm_text)\n",
    "    else:\n",
    "        print(\"Error: Invalid response from LLM.\")\n",
    "    end_time = time.time()\n",
    "    print(f\"\\nTime taken: {end_time - start_time:.2f} seconds\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093b681b",
   "metadata": {},
   "source": [
    "## 9. Play and Explore\n",
    "\n",
    "- Change `USER_TEXT` to ask any question about your picture.\n",
    "- Swap in a different image.\n",
    "- Compare models easily!\n",
    "\n",
    "\n",
    "## üßë‚Äçüíª Project Ideas for Practice\n",
    "\n",
    "Below are some fun project prompts. Try one (or all) after you run a basic image through the models!\n",
    "\n",
    "1. **Business Card ‚Üí vCard**\n",
    "   - Upload a photo of a business card.\n",
    "   - Write a prompt such as: \"Extract all the contact details from this business card and output as a vCard file.\"\n",
    "   - Post-process the model's output to save/download the .vcf file.\n",
    "\n",
    "2. **Agenda/Schedule ‚Üí Calendar File**\n",
    "   - Try an image of a handwritten or printed agenda.\n",
    "   - Prompt: \"Read and convert this agenda into an iCalendar (.ics) file.\"\n",
    "   - Save and import to your calendar app!\n",
    "\n",
    "3. **Driver's License ‚Üí CRM/Create Record**\n",
    "   - Upload an image of a driver's license (redact sensitive fields if needed).\n",
    "   - Prompt: \"Extract all key customer information for a CRM record.\"\n",
    "   - Map the LLM's result into your database or spreadsheet.\n",
    "\n",
    "If you see errors, double-check credentials or configurations. Refer to comments or docs for help.\n",
    "\n",
    "---\n",
    "**Happy building!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
