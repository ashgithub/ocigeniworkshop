{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAY 2 : RAG\n",
    "\n",
    "## Passing documents & citations\n",
    "\n",
    "### Supported models (https://docs.oracle.com/en-us/iaas/Content/generative-ai/chat-models.htm) \n",
    "- cohere.command-r-08-2024\n",
    "- cohere.command-r-plus-08-2024\n",
    "- cohere.command-a-03-2025\n",
    "  \n",
    "Will require using generic api: \n",
    "- meta.llama-3.1-405b-instruct\n",
    "- meta.llama-3.3-70b-instruct\n",
    "- meta.llama-3.2-90b-vision-instruct\n",
    "- meta.llama-4-maverick-17b-128e-instruct-fp8\n",
    "- meta.llama-4-scout-17b-16e-instruct\n",
    "  \n",
    "Questions use #generative-ai-users  or ##igiu-innovation-lab slack channels \n",
    "if you have errors running sample code reach out for help in #igiu-ai-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the  variables\n",
    "\n",
    "\n",
    "from oci.generative_ai_inference import GenerativeAiInferenceClient\n",
    "from oci.generative_ai_inference.models import *\n",
    "import oci\n",
    "import os,json\n",
    "from dotenv import load_dotenv\n",
    "from envyaml import EnvYAML\n",
    "\n",
    "#####\n",
    "#make sure your sandbox.yaml file is setup for your environment. You might have to specify the full path depending on  your `cwd` \n",
    "#####\n",
    "SANDBOX_CONFIG_FILE = \"sandbox.yaml\"\n",
    "load_dotenv()\n",
    "\n",
    "LLM_MODEL = \"cohere.command-a-03-2025\" \n",
    "llm_service_endpoint= \"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\"\n",
    "llm_client = None\n",
    "llm_payload = None\n",
    "\n",
    "\n",
    "PREAMBLE = \"provide factual answers based of document provided nclude citations if you can. Say you cant answer if the answer is not in provided documents \"\n",
    "MESSAGE = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scfg = EnvYAML(SANDBOX_CONFIG_FILE)\n",
    "if scfg is None or \"oci\" not in scfg or \"bucket\" not in scfg:\n",
    "    raise RuntimeError(\"Invalid sandbox configuration.\")\n",
    "\n",
    "#read the oci config\n",
    "config = oci.config.from_file(os.path.expanduser(scfg[\"oci\"][\"configFile\"]),scfg[\"oci\"][\"profile\"])\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set up Chat Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# chat request      \n",
    "llm_chat_request = CohereChatRequest()\n",
    "#llm_chat_request.preamble_override = PREAMBLE \n",
    "llm_chat_request.message = MESSAGE\n",
    "llm_chat_request.is_stream = False \n",
    "llm_chat_request.max_tokens = 500 # max token to generate, can lead to incomplete responses\n",
    "llm_chat_request.temperature = 1.0 # higer value menas more randon, defaul = 0.3\n",
    "#llm_chat_request.seed = 7555 # makes the best effort to make answer determininstic , not gaureented \n",
    "llm_chat_request.top_p = 0.7  # ensures only tokens with toptal probabely of p are considered, max value = 0.99, min 0.01, default 0.75\n",
    "llm_chat_request.top_k = 0  #Ensures that only top k tokens are considered, 0 turns it off, max = 500\n",
    "llm_chat_request.frequency_penalty = 0.0 # reduces the repeatedness of tokens max value 1.9=0, min 0,0\n",
    "#cohere_chat_request.documents = get_documents()  # will only answer from supplied documnets not frm its own knopwledge\n",
    "cohere_chat_request.citation_quality =  CohereChatRequest.CITATION_QUALITY_FAST # FAST or accurate\n",
    "#cohere_chat_request.citation_quality =  cohere_chat_request.CITATION_QUALITY_ACCURATE # FAST or accurate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "                 {\n",
    "                        \"title\": \"Oracle\",\n",
    "                        \"snippet\": \"Oracle database services and products offer customers cost-optimized and high-performance versions of Oracle Database, the world's leading converged, multi-model database management system, as well as in-memory, NoSQL and MySQL databases. Oracle Autonomous Database, available on premises via Oracle Cloud@Customer or in the Oracle Cloud Infrastructure, enables customers to simplify relational database environments and reduce management workloads.\",\n",
    "                        \"website\": \"https://www.oracle.com/database\",\n",
    "                        \"id\": \"ORA001\"\n",
    "                },\n",
    "                 {\n",
    "                        \"title\": \"Amazon\",\n",
    "                        \"snippet\": \"\"\" AWS provides the broadest selection of purpose-built databases allowing you to save, grow, and innovate faster.\n",
    "Purpose Built\n",
    "Choose from 15+ purpose-built database engines including relational, key-value, document, in-memory, graph, time series, wide column, and ledger databases.\n",
    "Performance at Scale\n",
    "Get relational databases that are 3-5X faster than popular alternatives, or non-relational databases that give you microsecond to sub-millisecond latency.\n",
    "Fully Managed\n",
    "AWS continuously monitors your clusters to keep your workloads running with self-healing storage and automated scaling, so that you can focus on application development.\n",
    "Secure & Highly Available\n",
    "AWS databases are built for business-critical, enterprise workloads, offering high availability, reliability, and security.\n",
    "\"\"\",\n",
    "                        \"website\": \"https://aws.amazon.com/free/database/e\",\n",
    "                        \"id\": \"AWS001\"\n",
    "                }\n",
    "]\n",
    "llm_chat_request.documents = docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up chat details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# set up chat details\n",
    "chat_detail = ChatDetails()\n",
    "chat_detail.serving_mode = OnDemandServingMode(model_id=LLM_MODEL)\n",
    "chat_detail.compartment_id =scfg[\"oci\"][\"compartment\"] \n",
    "chat_detail.chat_request = llm_chat_request\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the LLM client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set up the LLM client \n",
    "llm_client = GenerativeAiInferenceClient(\n",
    "                config=config,\n",
    "                service_endpoint=llm_service_endpoint,\n",
    "                retry_strategy=oci.retry.NoneRetryStrategy(),\n",
    "                timeout=(10,240))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask the question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************Chat Result**************************\n",
      "AWS provides the broadest selection of purpose-built databases that allow you to save, grow, and innovate faster. You can choose from 15+ purpose-built database engines including relational, key-value, document, in-memory, graph, time series, wide column, and ledger databases. The relational databases are 3-5X faster than popular alternatives, or non-relational databases that give you microsecond to sub-millisecond latency. AWS continuously monitors your clusters to keep your workloads running with self-healing storage and automated scaling, so that you can focus on application development. AWS databases are built for business-critical, enterprise workloads, offering high availability, reliability, and security.\n",
      "************************** Citations**************************\n",
      "[{\n",
      "  \"document_ids\": [\n",
      "    \"AWS001\"\n",
      "  ],\n",
      "  \"end\": 62,\n",
      "  \"start\": 17,\n",
      "  \"text\": \"broadest selection of purpose-built databases\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"AWS001\"\n",
      "  ],\n",
      "  \"end\": 113,\n",
      "  \"start\": 81,\n",
      "  \"text\": \"save, grow, and innovate faster.\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"AWS001\"\n",
      "  ],\n",
      "  \"end\": 168,\n",
      "  \"start\": 134,\n",
      "  \"text\": \"15+ purpose-built database engines\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"AWS001\"\n",
      "  ],\n",
      "  \"end\": 277,\n",
      "  \"start\": 179,\n",
      "  \"text\": \"relational, key-value, document, in-memory, graph, time series, wide column, and ledger databases.\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"AWS001\"\n",
      "  ],\n",
      "  \"end\": 344,\n",
      "  \"start\": 282,\n",
      "  \"text\": \"relational databases are 3-5X faster than popular alternatives\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"AWS001\"\n",
      "  ],\n",
      "  \"end\": 373,\n",
      "  \"start\": 349,\n",
      "  \"text\": \"non-relational databases\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"AWS001\"\n",
      "  ],\n",
      "  \"end\": 427,\n",
      "  \"start\": 388,\n",
      "  \"text\": \"microsecond to sub-millisecond latency.\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"AWS001\"\n",
      "  ],\n",
      "  \"end\": 467,\n",
      "  \"start\": 432,\n",
      "  \"text\": \"continuously monitors your clusters\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"AWS001\"\n",
      "  ],\n",
      "  \"end\": 546,\n",
      "  \"start\": 481,\n",
      "  \"text\": \"workloads running with self-healing storage and automated scaling\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"AWS001\"\n",
      "  ],\n",
      "  \"end\": 597,\n",
      "  \"start\": 564,\n",
      "  \"text\": \"focus on application development.\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"AWS001\"\n",
      "  ],\n",
      "  \"end\": 665,\n",
      "  \"start\": 616,\n",
      "  \"text\": \"built for business-critical, enterprise workloads\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"AWS001\"\n",
      "  ],\n",
      "  \"end\": 721,\n",
      "  \"start\": 676,\n",
      "  \"text\": \"high availability, reliability, and security.\"\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "#llm_chat_request.seed = 7555 # trting changing to see if we can reproduce teh opriginal response\n",
    "llm_chat_request.message = \"tell me more about AWS\"\n",
    "llm_response = llm_client.chat(chat_detail)\n",
    "llm_text = llm_response.data.chat_response.text\n",
    "        \n",
    "print(\"**************************Chat Result**************************\")\n",
    "#llm_text = llm_response.data.chat_response.text\n",
    "print(llm_response.data.chat_response.text)\n",
    "print(\"************************** Citations**************************\")\n",
    "print(llm_response.data.chat_response.citations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update the history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update history \n",
    "previous_chat_message = oci.generative_ai_inference.models.CohereUserMessage(message=\"Tell me something about Oracle.\")\n",
    "previous_chat_reply = oci.generative_ai_inference.models.CohereChatBotMessage(message=\"Oracle is one of the largest vendors in the enterprise IT market and the shorthand name of its flagship product. The database software sits at the center of many corporate IT\")\n",
    "        \n",
    "llm_chat_request.chat_history =  [previous_chat_message, previous_chat_reply]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ask the question again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oracle database services and products offer customers cost-optimized and high-performance versions of Oracle Database, the world's leading converged, multi-model database management system, as well as in-memory, NoSQL and MySQL databases.\n",
      "\n",
      "Oracle Autonomous Database, available on premises via Oracle Cloud@Customer or in the Oracle Cloud Infrastructure, enables customers to simplify relational database environments and reduce management workloads.\n"
     ]
    }
   ],
   "source": [
    "#llm_chat_request.documents = []\n",
    "llm_chat_request.message = \"tell me more about its databases\"\n",
    "llm_response = llm_client.chat(chat_detail)\n",
    "llm_text = llm_response.data.chat_response.text\n",
    "        \n",
    "print (llm_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** print response & citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************Chat Result**************************\n",
      "Oracle database services and products offer customers cost-optimized and high-performance versions of Oracle Database, the world's leading converged, multi-model database management system, as well as in-memory, NoSQL and MySQL databases.\n",
      "\n",
      "Oracle Autonomous Database, available on premises via Oracle Cloud@Customer or in the Oracle Cloud Infrastructure, enables customers to simplify relational database environments and reduce management workloads.\n",
      "************************** Citations**************************\n",
      "[{\n",
      "  \"document_ids\": [\n",
      "    \"ORA001\"\n",
      "  ],\n",
      "  \"end\": 68,\n",
      "  \"start\": 54,\n",
      "  \"text\": \"cost-optimized\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"ORA001\"\n",
      "  ],\n",
      "  \"end\": 89,\n",
      "  \"start\": 73,\n",
      "  \"text\": \"high-performance\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"ORA001\"\n",
      "  ],\n",
      "  \"end\": 188,\n",
      "  \"start\": 131,\n",
      "  \"text\": \"leading converged, multi-model database management system\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"ORA001\"\n",
      "  ],\n",
      "  \"end\": 210,\n",
      "  \"start\": 201,\n",
      "  \"text\": \"in-memory\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"ORA001\"\n",
      "  ],\n",
      "  \"end\": 217,\n",
      "  \"start\": 212,\n",
      "  \"text\": \"NoSQL\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"ORA001\"\n",
      "  ],\n",
      "  \"end\": 227,\n",
      "  \"start\": 222,\n",
      "  \"text\": \"MySQL\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"ORA001\"\n",
      "  ],\n",
      "  \"end\": 266,\n",
      "  \"start\": 247,\n",
      "  \"text\": \"Autonomous Database\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"ORA001\"\n",
      "  ],\n",
      "  \"end\": 315,\n",
      "  \"start\": 294,\n",
      "  \"text\": \"Oracle Cloud@Customer\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"ORA001\"\n",
      "  ],\n",
      "  \"end\": 353,\n",
      "  \"start\": 326,\n",
      "  \"text\": \"Oracle Cloud Infrastructure\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"ORA001\"\n",
      "  ],\n",
      "  \"end\": 417,\n",
      "  \"start\": 376,\n",
      "  \"text\": \"simplify relational database environments\"\n",
      "}, {\n",
      "  \"document_ids\": [\n",
      "    \"ORA001\"\n",
      "  ],\n",
      "  \"end\": 450,\n",
      "  \"start\": 422,\n",
      "  \"text\": \"reduce management workloads.\"\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "print(\"**************************Chat Result**************************\")\n",
    "#llm_text = llm_response.data.chat_response.text\n",
    "print(llm_response.data.chat_response.text)\n",
    "print(\"************************** Citations**************************\")\n",
    "print(llm_response.data.chat_response.citations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
