{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCI  RAG Agents\n",
    "\n",
    "### What this file does:\n",
    "Demonstrates using OCI Generative AI Agent Runtime service for out-of-the-box RAG with a shared knowledge base and citations.\n",
    "\n",
    "**Documentation to reference:**\n",
    "- OCI GenAI Agents: https://docs.oracle.com/en-us/iaas/Content/generative-ai-agents/home.htm\n",
    "- Agent Runtime API: https://docs.oracle.com/en-us/iaas/api/#/en/generative-ai-agent-runtime/20240531/\n",
    "- OCI Python SDK: https://github.com/oracle/oci-python-sdk/tree/master/src/oci/generative_ai_agent_runtime\n",
    "\n",
    "**Relevant slack channels:**\n",
    "- #generative-ai-agent-users or #igiu-innovation-lab: *For questions*\n",
    "- #igiu-ai-learning: *For errors or help*\n",
    "\n",
    "**Env setup:**\n",
    "- sandbox.yaml: Needs \"oci\" (configFile, profile) and \"agent\" (endpoint) sections.\n",
    "- .env: Load environment variables if needed.\n",
    "- Knowledge base: Upload docs via OCI console (see rag_agents.md).\n",
    "- configure cwd for jupyter match your workspace python code: \n",
    "    -  vscode menu -> Settings > Extensions > Jupyter > Notebook File Root\n",
    "    -  change from `${fileDirname}` to `${workspaceFolder}`\n",
    "\n",
    "\n",
    "**How to run in notebook:**\n",
    "- Ensure dependencies installed (uv sync).\n",
    "- Run cells in order.\n",
    "- Update sandbox.yaml with your agent endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from oci.generative_ai_agent_runtime import GenerativeAiAgentRuntimeClient\n",
    "import oci\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from envyaml import EnvYAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "SANDBOX_CONFIG_FILE = \"sandbox.yaml\"\n",
    "load_dotenv()\n",
    "GENAI_URL = \"https://agent-runtime.generativeai.us-chicago-1.oci.oraclecloud.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load config and initialize the agent client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "scfg = EnvYAML(SANDBOX_CONFIG_FILE)\n",
    "if scfg is None or \"oci\" not in scfg or \"bucket\" not in scfg:\n",
    "    raise RuntimeError(\"Invalid sandbox configuration.\")\n",
    "\n",
    "config = oci.config.from_file(os.path.expanduser(scfg[\"oci\"][\"configFile\"]), scfg[\"oci\"][\"profile\"])\n",
    "endpoint = scfg[\"agent\"][\"endpoint\"]\n",
    "\n",
    "# Initialize agent client\n",
    "llm_agent_client = GenerativeAiAgentRuntimeClient(\n",
    "    config=config,\n",
    "    service_endpoint=GENAI_URL,\n",
    "    retry_strategy=oci.retry.NoneRetryStrategy(),\n",
    "    timeout=(10, 240)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a session for conversational context.\n",
    "# Create session details\n",
    "create_session_details = oci.generative_ai_agent_runtime.models.CreateSessionDetails(\n",
    "    display_name=\"Inno Lab C2M Agent\",\n",
    "    description=\"The agent has access to C2M documentation and can answer questions on it.\"\n",
    ")\n",
    "\n",
    "# Create session\n",
    "create_session_response = llm_agent_client.create_session(create_session_details, endpoint)\n",
    "session_id = create_session_response.data.id\n",
    "print(f\"Session created: {session_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Ask Questions and Get Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample question 1\n",
    "chat_detail = oci.generative_ai_agent_runtime.models.ChatDetails()\n",
    "chat_detail.user_message = \"what industries do we serve\"\n",
    "chat_detail.session_id = session_id\n",
    "\n",
    "chat_response = llm_agent_client.chat(endpoint, chat_detail)\n",
    "result = chat_response.data.message.content\n",
    "\n",
    "print(\"****** Citation ******\")\n",
    "print(result.citations)\n",
    "print(\"****** Answer ******\")\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample question 2 (follow-up)\n",
    "chat_detail = oci.generative_ai_agent_runtime.models.ChatDetails()\n",
    "chat_detail.user_message = \"tell me more about the second industry\"\n",
    "chat_detail.session_id = session_id\n",
    "\n",
    "chat_response = llm_agent_client.chat(endpoint, chat_detail)\n",
    "result = chat_response.data.message.content\n",
    "\n",
    "print(\"****** Citation ******\")\n",
    "print(result.citations)\n",
    "print(\"****** Answer ******\")\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation Section\n",
    "Try these to learn more:\n",
    "- Add documents to the knowledge base via OCI console.\n",
    "- Ingest new documents and rerun queries.\n",
    "- Switch to sessionless endpoint (update sandbox.yaml).\n",
    "- Ask domain-specific questions (e.g., from uploaded docs).\n",
    "- Try code-based queries (e.g., SQL or programming)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises\n",
    "1. **Add Documents**: Upload PDFs with images/charts to knowledge base and query.\n",
    "2. **Ingest and Play**: Ingest docs, chat, and experiment with responses.\n",
    "3. **Code Queries**: Try asking about code snippets or technical docs.\n",
    "4. **Discussion**: How does agent RAG compare to home-grown RAG in ease and citations?\n",
    "\n",
    "For help, reach out in #igiu-innovation-lab or #igiu-ai-learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
