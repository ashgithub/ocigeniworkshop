{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCI Vision API ‚Äì Image Analysis (Beginner Notebook)\n",
    "\n",
    "### What this file does:\n",
    "Analyze images using OCI Vision for object detection, text recognition, classification, and face detection. This walkthrough notebook is adapted from the logic in `vision/oci_vision.py`.\n",
    "\n",
    "**Documentation to reference:**\n",
    "- OCI Vision: https://docs.oracle.com/en-us/iaas/Content/vision/using/home.htm\n",
    "- OCI Python SDK: https://github.com/oracle/oci-python-sdk/tree/master/src/oci/ai_vision\n",
    "\n",
    "**Relevant slack channels:**\n",
    "- #oci_ai_vision_support: *for OCI Vision API questions*\n",
    "- #igiu-innovation-lab: *general discussions on your project*\n",
    "- #igiu-ai-learning: *help with sandbox environment or help with running this code*\n",
    "\n",
    "**Env setup:**\n",
    "- sandbox.yaml: Contains OCI config, compartment, and bucket details.\n",
    "- .env: Load environment variables if needed.\n",
    "- configure cwd for jupyter match your workspace python code: \n",
    "    -  vscode menu -> Settings > Extensions > Jupyter > Notebook File Root\n",
    "    -  change from `${fileDirname}` to `${workspaceFolder}`\n",
    "\n",
    "\n",
    "**How to run in notebook:**\n",
    "- Make sure your runtime environment has all dependencies and access to required config files.\n",
    "- Run the notebook cells in order.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Requirements\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Environment Setup:** Before interacting with OCI services, you need to configure your environment with credentials, compartment IDs, and bucket details. This is typically done via a YAML config file (sandbox.yaml) and environment variables.\n",
    "- **Dependencies:** Install necessary libraries like the OCI SDK and configuration loaders.\n",
    "- **Libraries:** Use packages for config management, environment variables, and OCI interactions.\n",
    "\n",
    "In this step, we'll install dependencies and import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from envyaml import EnvYAML\n",
    "from pathlib import Path\n",
    "import oci\n",
    "from oci.object_storage import ObjectStorageClient\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Libraries imported and environment loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load OCI/Sandbox Configuration\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Configuration Loading:** Securely load settings from a config file to authenticate and specify resources without hardcoding credentials.\n",
    "- **OCI Config:** Includes paths to config files, profiles, compartments, and bucket details.\n",
    "- **Error Handling:** Validate that the config is loaded correctly to avoid runtime errors.\n",
    "\n",
    "In this step, we'll load and validate the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and load configuration\n",
    "# Make sure your sandbox.yaml file is set up for your environment. You might have to specify the full path depending on your `cwd`.\n",
    "# You can also try making your cwd for jupyter match your workspace python code:\n",
    "# vscode menu -> Settings > Extensions > Jupyter > Notebook File Root\n",
    "# change from ${fileDirname} to ${workspaceFolder}\n",
    "\n",
    "SANDBOX_CONFIG_FILE = \"sandbox.yaml\"\n",
    "DEFAULT_FILE = Path(\"./vision/receipt.png\")\n",
    "\n",
    "def load_config(config_path):\n",
    "    try:\n",
    "        return EnvYAML(config_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Configuration file '{config_path}' not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading config: {e}\")\n",
    "        return None\n",
    "\n",
    "scfg = load_config(SANDBOX_CONFIG_FILE)\n",
    "assert scfg is not None and 'oci' in scfg and 'bucket' in scfg, \"Check your sandbox.yaml config!\"\n",
    "oci_cfg = oci.config.from_file(os.path.expanduser(scfg[\"oci\"][\"configFile\"]), scfg[\"oci\"][\"profile\"])\n",
    "bucket_cfg = scfg[\"bucket\"]\n",
    "compartment_id = scfg[\"oci\"][\"compartment\"]\n",
    "\n",
    "print(\"Configuration loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Select and Display an Image\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Image Selection:** Choose the image file to analyze. Ensure it's in a supported format (e.g., JPEG, PNG).\n",
    "- **Display:** Visualize the image to confirm it's the correct one before processing.\n",
    "- **Path Handling:** Use Path objects for robust file path management.\n",
    "\n",
    "In this step, we'll select the image and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the image file\n",
    "# Change this if you want to use another image:\n",
    "FILE_PATH = Path(\"vision/receipt.png\")\n",
    "# Example: FILE_PATH = Path(\"vision/dussera-b.jpg\")\n",
    "\n",
    "print(f\"Selected image: {FILE_PATH}\")\n",
    "\n",
    "# Display the image\n",
    "display(Image(filename=str(FILE_PATH)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Upload Image to OCI Object Storage\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Object Storage:** OCI's scalable storage for files. Images must be uploaded here for analysis.\n",
    "- **Bucket and Namespace:** Organize files in buckets within a namespace for access control.\n",
    "- **Prefix:** Use prefixes to categorize objects, similar to folders.\n",
    "\n",
    "In this step, we'll upload the selected image to Object Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to upload file to Object Storage\n",
    "def upload(oci_cfg, bucket_cfg, file_path):\n",
    "    if not file_path.exists():\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        return False\n",
    "    object_storage_client = ObjectStorageClient(oci_cfg)\n",
    "    print(f\"Uploading file {file_path} ...\")\n",
    "    object_storage_client.put_object(\n",
    "        bucket_cfg[\"namespace\"], \n",
    "        bucket_cfg[\"bucketName\"], \n",
    "        f\"{bucket_cfg['prefix']}/{file_path.name}\", \n",
    "        open(file_path, 'rb')\n",
    "    )\n",
    "    print(\"Upload completed!\")\n",
    "    return True\n",
    "\n",
    "# Perform the upload\n",
    "uploaded = upload(oci_cfg, bucket_cfg, FILE_PATH)\n",
    "if not uploaded:\n",
    "    raise ValueError(\"Upload failed. Check your image and configuration.\")\n",
    "else:\n",
    "    print(\"Image uploaded successfully to Object Storage.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Set Up Analysis Features\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Vision Service Features:** OCI Vision can perform multiple analyses: classification (e.g., image type), object detection, text detection (OCR), and face detection.\n",
    "- **Feature Selection:** Choose which analyses to run based on your needs to optimize cost and performance.\n",
    "- **Request Details:** Specify the image location and compartment for processing.\n",
    "\n",
    "In this step, we'll define the features and prepare the analysis request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions for image location and analysis details\n",
    "def get_image_location(bucket_cfg, file_name):\n",
    "    image = oci.ai_vision.models.ObjectStorageImageDetails(\n",
    "        source=\"OBJECT_STORAGE\",\n",
    "        namespace_name=bucket_cfg[\"namespace\"],\n",
    "        bucket_name=bucket_cfg[\"bucketName\"],\n",
    "        object_name=f\"{bucket_cfg['prefix']}/{file_name}\"\n",
    "    )\n",
    "    return image\n",
    "\n",
    "def get_analyze_image_details(features, compartment_id, bucket_cfg, file_name):\n",
    "    details = oci.ai_vision.models.AnalyzeImageDetails(\n",
    "        features=features,\n",
    "        image=get_image_location(bucket_cfg, file_name),\n",
    "        compartment_id=compartment_id\n",
    "    )\n",
    "    return details\n",
    "\n",
    "# Configure features: classification, object detection, text detection, face detection\n",
    "features = [\n",
    "    oci.ai_vision.models.ImageClassificationFeature(),\n",
    "    oci.ai_vision.models.ImageObjectDetectionFeature(),\n",
    "    oci.ai_vision.models.ImageTextDetectionFeature(),\n",
    "    oci.ai_vision.models.FaceDetectionFeature()\n",
    "]\n",
    "\n",
    "print(\"Analysis features configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Analyze Image\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Synchronous Analysis:** OCI Vision processes images in real-time via API calls.\n",
    "- **Client Initialization:** Create a client with your OCI config to interact with the service.\n",
    "- **Response Handling:** Capture the analysis results, including status and data.\n",
    "\n",
    "In this step, we'll send the image for analysis and receive the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Vision client\n",
    "vision_client = oci.ai_vision.AIServiceVisionClient(config=oci_cfg)\n",
    "\n",
    "# Perform the analysis\n",
    "try:\n",
    "    response = vision_client.analyze_image(\n",
    "        get_analyze_image_details(features, compartment_id, bucket_cfg, FILE_PATH.name)\n",
    "    )\n",
    "    if response:\n",
    "        print(\"Analysis complete! (Status: \", response.status, \")\")\n",
    "    else:\n",
    "        print(\"No response received.\")\n",
    "        response = None\n",
    "except Exception as e:\n",
    "    print(f\"Error during analysis: {e}\")\n",
    "    response = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Parse and Print Results\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Result Parsing:** Extract and display insights from the response, such as classifications, detected objects, text, and faces.\n",
    "- **Confidence Scores:** Each detection includes a confidence level to gauge reliability.\n",
    "- **Structured Output:** Present data in a readable format for easy interpretation.\n",
    "\n",
    "In this step, we'll parse the analysis results and display them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse and display vision response\n",
    "def parse_vision_response(data):\n",
    "    print(\"\\nOCI Vision Analysis Results:\")\n",
    "    labels = getattr(data, 'labels', None)\n",
    "    if labels:\n",
    "        print(\"\\nClassifications:\")\n",
    "        for label in labels:\n",
    "            print(f\"  - {label.name}: {label.confidence:.2f}\")\n",
    "    image_objects = getattr(data, 'image_objects', None)\n",
    "    if image_objects:\n",
    "        print(\"\\nDetected Objects:\")\n",
    "        for obj in image_objects:\n",
    "            print(f\"  - {obj.name} : {obj.confidence:.2f}\")\n",
    "    image_text = getattr(data, 'image_text', None)\n",
    "    if image_text and hasattr(image_text, 'lines'):\n",
    "        print(\"\\nDetected Text Lines:\")\n",
    "        for line in image_text.lines:\n",
    "            print(f\"  - {line.text}: {line.confidence:.2f}\")\n",
    "    detected_faces = getattr(data, 'detected_faces', None)\n",
    "    if detected_faces:\n",
    "        print(\"\\nDetected Faces:\")\n",
    "        for face in detected_faces:\n",
    "            print(f\"  - Face confidence: {face.confidence:.2f} : Quality {face.quality_score:.2f}\")\n",
    "    if not any([labels, image_objects, image_text, detected_faces]):\n",
    "        print(\"No features detected in the image.\")\n",
    "\n",
    "# Parse the results\n",
    "if response is not None and hasattr(response, 'data'):\n",
    "    parse_vision_response(response.data)\n",
    "else:\n",
    "    print(\"No results to parse.\")\n",
    "\n",
    "print(\"\\nParsing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Done! Next Steps\n",
    "\n",
    "- Try different images or text files for analysis.\n",
    "- Adapt feature selection for narrower use-cases (object-detection only, for instance).\n",
    "- Explore downstream automation: parse response dicts for structured results!\n",
    "\n",
    "## üßë‚Äçüíª Project Ideas for Practice\n",
    "\n",
    "Below are some practical project prompts. Try one (or all) after you run a basic image through the models!\n",
    "\n",
    "1. **OCR a Receipt**: Extract text from receipts and parse into structured data (date, amount, items).\n",
    "2. **Document Type Identification**: Classify uploaded documents (e.g., receipts, invoices, IDs).\n",
    "3. **ID Verification**: Confirm ID matches the user based on name and DOB from detected text.\n",
    "4. **Accessibility Tool**: Describe images for visually impaired users using object detection and text.\n",
    "5. **Content Moderation**: Detect inappropriate objects or text in images for automated filtering.\n",
    "\n",
    "If you have OCI API errors, check your config, permissions, and credentials."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
