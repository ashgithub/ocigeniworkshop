{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCI Document Understanding (Beginner Notebook)\n",
    "\n",
    "### What this file does:\n",
    "Analyze receipts, invoices, or documents in your OCI bucket with Oracle's Gen AI Document Understanding. This walkthrough notebook is adapted from the logic in `vision/oci_document_understanding.py`.\n",
    "\n",
    "**Documentation to reference:**\n",
    "- OCI Document Understanding: https://docs.oracle.com/en-us/iaas/Content/document-understanding/using/home.htm\n",
    "- OCI Python SDK: https://github.com/oracle/oci-python-sdk/tree/master/src/oci/ai_document\n",
    "\n",
    "**Relevant slack channels:**\n",
    "- #oci_ai_document_service_users: *for OCI Document Understanding API questions*\n",
    "- #igiu-innovation-lab: *general discussions on your project*\n",
    "- #igiu-ai-learning: *help with sandbox environment or help with running this code*\n",
    "\n",
    "**Env setup:**\n",
    "- sandbox.yaml: Contains OCI config, compartment, and bucket details.\n",
    "- .env: Load environment variables if needed.\n",
    "- configure cwd for jupyter match your workspace python code: \n",
    "    -  vscode menu -> Settings > Extensions > Jupyter > Notebook File Root\n",
    "    -  change from `${fileDirname}` to `${workspaceFolder}`\n",
    "\n",
    "\n",
    "**How to run in notebook:**\n",
    "- Make sure your runtime environment has all dependencies and access to required config files.\n",
    "- Run the notebook cells in order.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Configuration\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Environment Setup:** Before interacting with OCI services, you need to configure your environment with credentials, compartment IDs, and bucket details. This is typically done via a YAML config file (sandbox.yaml) and environment variables.\n",
    "- **Dependencies:** Install necessary libraries like the OCI SDK and configuration loaders.\n",
    "- **Configuration Loading:** Load settings securely to authenticate and specify resources.\n",
    "\n",
    "In this step, we'll install dependencies, load environment variables, and configure our OCI client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from envyaml import EnvYAML\n",
    "from pathlib import Path\n",
    "import oci\n",
    "from oci.object_storage import ObjectStorageClient\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and load configuration\n",
    "# Make sure your sandbox.yaml file is set up for your environment. You might have to specify the full path depending on your `cwd`.\n",
    "# You can also try making your cwd for jupyter match your workspace python code:\n",
    "# vscode menu -> Settings > Extensions > Jupyter > Notebook File Root\n",
    "# change from ${fileDirname} to ${workspaceFolder}\n",
    "\n",
    "SANDBOX_CONFIG_FILE = \"sandbox.yaml\"\n",
    "FILE_TO_ANALYZE = Path(\"./vision/receipt.png\")  # Change to your input file if desired\n",
    "\n",
    "def load_config(config_path):\n",
    "    try:\n",
    "        with open(config_path, 'r') as f:\n",
    "            return EnvYAML(config_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Configuration file '{config_path}' not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading config: {e}\")\n",
    "        return None\n",
    "\n",
    "scfg = load_config(SANDBOX_CONFIG_FILE)\n",
    "assert scfg is not None and 'oci' in scfg and 'bucket' in scfg, \"Check your sandbox.yaml config!\"\n",
    "oci_cfg = oci.config.from_file(os.path.expanduser(scfg[\"oci\"][\"configFile\"]), scfg[\"oci\"][\"profile\"])\n",
    "bucket_cfg = scfg[\"bucket\"]\n",
    "compartment_id = scfg[\"oci\"][\"compartment\"]\n",
    "\n",
    "print(\"Configuration loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Upload Document to Object Storage\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Object Storage:** OCI's Object Storage is a scalable service for storing files like images or PDFs. Before processing, documents must be uploaded here.\n",
    "- **Bucket and Namespace:** Organize files in buckets within a namespace for secure access.\n",
    "- **Prefix:** Use prefixes to organize objects, similar to folders.\n",
    "\n",
    "In this step, we'll upload the document file to your OCI Object Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to upload file to Object Storage\n",
    "def upload(oci_cfg, bucket_cfg, file_path):\n",
    "    if not file_path.exists():\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        return False\n",
    "    object_storage_client = ObjectStorageClient(oci_cfg)\n",
    "    print(f\"Uploading file {file_path} ...\")\n",
    "    object_storage_client.put_object(\n",
    "        bucket_cfg['namespace'],\n",
    "        bucket_cfg['bucketName'],\n",
    "        f\"{bucket_cfg['prefix']}/{file_path.name}\",\n",
    "        open(file_path, 'rb')\n",
    "    )\n",
    "    print(\"Upload completed!\")\n",
    "    return True\n",
    "\n",
    "# Perform the upload\n",
    "uploaded = upload(oci_cfg, bucket_cfg, FILE_TO_ANALYZE)\n",
    "if not uploaded:\n",
    "    raise Exception(\"Upload failed. Check file path and sandbox.yaml config.\")\n",
    "else:\n",
    "    print(\"File uploaded successfully to Object Storage.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure Document Understanding Request\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Document Understanding Service:** This OCI AI service analyzes documents to extract text, classify types, detect languages, pull key-value pairs, and identify tables.\n",
    "- **Features:** Specify which analyses to perform (e.g., text extraction, classification).\n",
    "- **Processor Job:** A job that processes the document asynchronously.\n",
    "\n",
    "In this step, we'll set up the client and define the processing features and locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Document Understanding client\n",
    "dus_client = oci.ai_document.AIServiceDocumentClientCompositeOperations(\n",
    "    oci.ai_document.AIServiceDocumentClient(config=oci_cfg)\n",
    ")\n",
    "\n",
    "print(\"Document Understanding client initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions for input and output locations\n",
    "def get_input_location(bucket_cfg):\n",
    "    object_location = oci.ai_document.models.ObjectLocation()\n",
    "    object_location.namespace_name = bucket_cfg[\"namespace\"]\n",
    "    object_location.bucket_name = bucket_cfg[\"bucketName\"]\n",
    "    object_location.object_name = f\"{bucket_cfg['prefix']}/{os.path.basename(FILE_TO_ANALYZE)}\"\n",
    "    return object_location\n",
    "\n",
    "def get_output_location(bucket_cfg):\n",
    "    object_location = oci.ai_document.models.OutputLocation()\n",
    "    object_location.namespace_name = bucket_cfg[\"namespace\"]\n",
    "    object_location.bucket_name = bucket_cfg[\"bucketName\"]\n",
    "    object_location.prefix = f\"{bucket_cfg['prefix']}\"\n",
    "    return object_location\n",
    "\n",
    "def create_processor(features, prefix, compartmentid, bucket_cfg):\n",
    "    display_name = f\"{prefix}-test\"\n",
    "    job_details = oci.ai_document.models.CreateProcessorJobDetails(\n",
    "        display_name=display_name,\n",
    "        compartment_id=compartmentid,\n",
    "        input_location=oci.ai_document.models.ObjectStorageLocations(\n",
    "            object_locations=[get_input_location(bucket_cfg)]),\n",
    "        output_location=get_output_location(bucket_cfg),\n",
    "        processor_config=oci.ai_document.models.GeneralProcessorConfig(features=features)\n",
    "    )\n",
    "    return job_details\n",
    "\n",
    "# Set features: classification, language, key-value, tables, text\n",
    "features = [\n",
    "    oci.ai_document.models.DocumentClassificationFeature(),\n",
    "    oci.ai_document.models.DocumentLanguageClassificationFeature(),\n",
    "    oci.ai_document.models.DocumentKeyValueExtractionFeature(),\n",
    "    oci.ai_document.models.DocumentTableExtractionFeature(),\n",
    "    oci.ai_document.models.DocumentTextExtractionFeature()\n",
    "]\n",
    "prefix = bucket_cfg['prefix']\n",
    "\n",
    "print(\"Processing features configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Submit Processing Job\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Asynchronous Processing:** Document analysis jobs run in the background to handle large files without blocking your code.\n",
    "- **Lifecycle States:** Jobs go through states like 'in progress', 'succeeded', or 'failed'.\n",
    "- **Waiting for Completion:** Use waiters to poll until the job finishes.\n",
    "\n",
    "In this step, we'll submit the job and wait for it to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback for job status updates\n",
    "def create_processor_job_callback(times_called, response):\n",
    "    print(\"Waiting for processor lifecycle state to go into succeeded state:\", getattr(response, 'data', response))\n",
    "\n",
    "# Submit the job and wait\n",
    "processor_res = dus_client.create_processor_job_and_wait_for_state(\n",
    "    create_processor_job_details=create_processor(features, prefix, compartment_id, bucket_cfg),\n",
    "    wait_for_states=[oci.ai_document.models.ProcessorJob.LIFECYCLE_STATE_SUCCEEDED],\n",
    "    waiter_kwargs={\"wait_callback\": create_processor_job_callback}\n",
    ")\n",
    "\n",
    "# Check job result\n",
    "processor_job = None\n",
    "if (processor_res and processor_res is not oci.util.Sentinel):\n",
    "    data = getattr(processor_res, 'data', None)\n",
    "    request_id = getattr(processor_res, 'request_id', None)\n",
    "    if (data is not None and data is not oci.util.Sentinel and\n",
    "        hasattr(data, 'lifecycle_state') and\n",
    "        data.lifecycle_state == oci.ai_document.models.ProcessorJob.LIFECYCLE_STATE_SUCCEEDED):\n",
    "        processor_job = data\n",
    "        print(f\"Processor job succeeded with lifecycle state: {processor_job.lifecycle_state} and request ID: {request_id}.\")\n",
    "    else:\n",
    "        print(\"Processor job did not succeed.\")\n",
    "else:\n",
    "    print(\"Processor job creation failed or timed out.\")\n",
    "\n",
    "if processor_job is None:\n",
    "    raise Exception(\"Processor job failed to complete successfully.\")\n",
    "else:\n",
    "    print(\"Job completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Retrieve and Display Results\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Output Storage:** Results are stored back in Object Storage as JSON files.\n",
    "- **Result Structure:** Includes extracted data like text, fields, and classifications.\n",
    "- **Downloading Results:** Retrieve the JSON output for further processing.\n",
    "\n",
    "In this step, we'll download the analysis results from Object Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Object Storage client for retrieval\n",
    "object_storage_client = oci.object_storage.ObjectStorageClient(config=oci_cfg)\n",
    "namespace = bucket_cfg['namespace']\n",
    "bucket_name = bucket_cfg['bucketName']\n",
    "\n",
    "# Construct result object name\n",
    "if processor_job is not None and hasattr(processor_job, 'id'):\n",
    "    result_object_name = (\n",
    "        f\"{prefix}/{processor_job.id}/{namespace}_{bucket_name}/results/{prefix}/{FILE_TO_ANALYZE.name}.json\"\n",
    "    )\n",
    "    response = object_storage_client.get_object(\n",
    "        namespace_name=namespace,\n",
    "        bucket_name=bucket_name,\n",
    "        object_name=result_object_name\n",
    "    )\n",
    "    if response is not None and hasattr(response, 'data') and hasattr(response.data, 'content'):\n",
    "        json_data = json.loads(response.data.content.decode('utf-8'))\n",
    "        print(\"Analysis complete! Document Understanding Results:\")\n",
    "        print(json.dumps(json_data, indent=2))\n",
    "    else:\n",
    "        print('Failed to retrieve results or parse.' )\n",
    "        json_data = None\n",
    "else:\n",
    "    print('Error: Invalid processor job.')\n",
    "    json_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Parse and Summarize Key Results\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Result Parsing:** Extract meaningful information from the JSON output, such as document type, language, and key fields.\n",
    "- **Field Types:** Handle different extractions like key-value pairs and line items.\n",
    "- **Summarization:** Present data in a readable format for quick insights.\n",
    "\n",
    "In this step, we'll parse the JSON results and display a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse and summarize response\n",
    "def parse_response(json_data):\n",
    "    if json_data is None:\n",
    "        print(\"No data to parse.\")\n",
    "        return\n",
    "    doc_type = json_data.get('detectedDocumentTypes', [{}])[0].get('documentType', 'N/A')\n",
    "    lang = json_data.get('detectedLanguages', [{}])[0].get('language', 'N/A')\n",
    "    print(f\"Detected Document Type: {doc_type}\")\n",
    "    print(f\"Detected Language: {lang}\")\n",
    "    pages = json_data.get('pages', [])\n",
    "    if not pages:\n",
    "        print(\"No pages found in response.\")\n",
    "        return\n",
    "    for page_idx, page in enumerate(pages, start=1):\n",
    "        print(f\"\\n--- Page {page_idx} ---\")\n",
    "        fields = page.get('documentFields', [])\n",
    "        if not fields:\n",
    "            print(\"No document fields extracted on this page.\")\n",
    "            continue\n",
    "        for field in fields:\n",
    "            if field['fieldType'] == 'KEY_VALUE':\n",
    "                label = field['fieldLabel']['name']\n",
    "                value = field['fieldValue']\n",
    "                if value['valueType'] == 'STRING':\n",
    "                    print(f\"{label}: {value['text']}\")\n",
    "                elif value['valueType'] == 'NUMBER':\n",
    "                    print(f\"{label}: {value['value']}\")\n",
    "                elif value['valueType'] == 'DATE':\n",
    "                    print(f\"{label}: {value['text']} ({value['value']})\")\n",
    "            elif field['fieldType'] == 'LINE_ITEM_GROUP':\n",
    "                print(f\"{field['fieldLabel']['name']}:\")\n",
    "                value = field['fieldValue']\n",
    "                items = value.get('items', [])\n",
    "                for item in items:\n",
    "                    name = next((f['fieldValue']['text'] for f in item['fieldValue']['items'] if f['fieldLabel']['name']=='Name'), 'N/A')\n",
    "                    quantity = next((f['fieldValue']['value'] for f in item['fieldValue']['items'] if f['fieldLabel']['name']=='Quantity'), 'N/A')\n",
    "                    unit_price = next((f['fieldValue']['value'] for f in item['fieldValue']['items'] if f['fieldLabel']['name']=='UnitPrice'), 'N/A')\n",
    "                    amount = next((f['fieldValue']['value'] for f in item['fieldValue']['items'] if f['fieldLabel']['name']=='Amount'), 'N/A')\n",
    "                    print(f\"  - {name}: Qty {quantity} @ ${unit_price} = ${amount}\")\n",
    "            else:\n",
    "                print(f\"Unsupported field type: {field['fieldType']}\")\n",
    "\n",
    "# Parse the results\n",
    "parse_response(json_data)\n",
    "print(\"\\nParsing and summarization complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play and Explore\n",
    "\n",
    "- Swap in a different image or PDF by changing `FILE_TO_ANALYZE` (try invoices, forms, or handwritten documents).\n",
    "- Use both printed and handwritten documents to see how the model handles different text styles.\n",
    "- Try documents in different languages (ensure the language is supported).\n",
    "- Modify the `features` list to focus on specific extractions (e.g., remove table extraction for text-only documents).\n",
    "- Experiment with larger PDFs or multi-page documents.\n",
    "\n",
    "## üßë‚Äçüíª Project Ideas for Practice\n",
    "\n",
    "Below are some practical project prompts. Try one (or all) after you run a basic document through the models!\n",
    "\n",
    "1. **Automated Receipt Processing**: Mimic the receipt entry that Oracle Expenses uses by extracting key fields like date, amount, vendor, and items. Save the structured data to a database or spreadsheet.\n",
    "2. **Table Data Extraction**: Read tables from PDF documents and convert them to CSV or JSON format. Useful for financial reports or schedules.\n",
    "3. **Document Classification System**: Build a tool that classifies uploaded documents (e.g., receipts, invoices, contracts) and routes them to appropriate processing workflows.\n",
    "4. **Form Data Digitization**: Create a system to extract key-value pairs from forms and populate them into web forms or databases.\n",
    "5. **Multi-Language Document Processing**: Develop a pipeline that detects language, extracts text, and translates it if needed.\n",
    "\n",
    "If you see errors, double-check credentials or configurations. Refer to comments or docs for help.\n",
    "\n",
    "---\n",
    "**Happy building!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
